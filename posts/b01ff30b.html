<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>CS231A-Notes</title><meta name="description" content="Keep Learning"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/blog/images/favicon.png"><link rel="stylesheet" href="/blog/style/common/bulma.css"><link rel="stylesheet" href="/blog/style/base.css"><link rel="stylesheet" href="/blog/style/common/helper.css"><script src="/blog/js/common.js"></script><link rel="stylesheet" href="/blog/style/post.css"><link rel="stylesheet" href="/blog/style/themes/highlight-theme-light.css"><script src="/blog/js/highlight.pack.js"></script><meta name="description" content="CS231A Lecture Notes
Lec2 Camera Model
Pinhole cameras &amp;amp; lenses

Pinhole Camera:

Aperture is too large: blur picture
Aperture too small: not enough lights

Cameras &amp;amp; lens

a sepcific distance to ???
all rays of light that are emitted by some point P are refracted by the lens such that they converge to a single point P ′


all the x, x' are in came.."><meta name="generator" content="Hexo 5.4.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/blog/">Jiani Wang's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">CS231A-Notes</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Click back to the top</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/blog/about">About</a></h3><h3 class="is-inline-block"><a href="/blog/">Blog</a></h3><h3 class="is-inline-block"><a href="/blog/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/blog/about">About</a></h3><h3 class="is-inline-block"><a href="/blog/">Blog</a></h3><h3 class="is-inline-block"><a href="/blog/archives">Archives</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#cs231a-lecture-notes"><span class="toc-text">CS231A Lecture Notes</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#lec2-camera-model"><span class="toc-text">Lec2 Camera Model</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#pinhole-cameras-lenses"><span class="toc-text">Pinhole cameras &amp; lenses</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#the-geometry-of-pinhole-camera"><span class="toc-text">The geometry of pinhole camera</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec3-camare-model2-camera-calibration"><span class="toc-text">Lec3 Camare Model2 &amp; Camera Calibration</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#camera-calibration"><span class="toc-text">Camera Calibration</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec4-single-view-metrology"><span class="toc-text">Lec4 Single View Metrology</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#vanishing-points-and-lines"><span class="toc-text">Vanishing points and lines</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#estimating-geometry-from-a-single-image"><span class="toc-text">Estimating geometry from a single image</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec5-epipolar-geometry"><span class="toc-text">Lec5 Epipolar Geometry</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec6-stereo-systems-multi-view-geometry"><span class="toc-text">Lec6 Stereo Systems&#x2F; Multi-view Geometry</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec7-multi-view-geometry"><span class="toc-text">Lec7 Multi-view Geometry</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#affine-sfm"><span class="toc-text">Affine SFM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#perspective-sfm"><span class="toc-text">Perspective SFM</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec8-active-stereo-volumetric-stereo"><span class="toc-text">Lec8 Active stereo &amp; Volumetric stereo</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec9-fitting-and-matching"><span class="toc-text">Lec9 Fitting and Matching</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec10-representations-and-representation-learning"><span class="toc-text">Lec10 Representations and Representation Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#summary"><span class="toc-text">Summary</span></a></li></ol></li></ol></li></ol></div><div class="column is-9"><header class="my-4"><a href="/blog/tags/CS231A"><i class="tag post-item-tag">CS231A</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">CS231A-Notes</h1><time class="has-text-grey" datetime="2022-02-13T06:02:41.000Z">2022-02-13</time><article class="mt-2 post-content"><h1 id="cs231a-lecture-notes">CS231A Lecture Notes</h1>
<h2 id="lec2-camera-model">Lec2 Camera Model</h2>
<h3 id="pinhole-cameras-lenses">Pinhole cameras &amp; lenses</h3>
<ul>
<li><p>Pinhole Camera:</p>
<ul>
<li><p>Aperture is too large: blur picture</p></li>
<li><p>Aperture too small: not enough lights</p></li>
</ul></li>
<li><p>Cameras &amp; lens</p>
<ul>
<li><p>a sepcific distance to ???</p></li>
<li><p>all rays of light that are emitted by some point P are refracted by the lens such that they converge to a single point P ′</p></li>
<li><p><img src="../images/image-20220211195215034.png" alt="image-20220211195215034"></p>
<ul>
<li>all the x, x' are in camera reference system</li>
</ul></li>
<li><p>Radial Distortion:</p>
<ul>
<li>noticebale for rays that apss throught the edge of the lens</li>
</ul></li>
<li><p>Is the projective transformation correspond to what we see in actural digital images: No</p>
<ul>
<li><p>points in the digital images are, in general, in a different reference system than those in the image plane.</p></li>
<li><p>digital images are divided into discrete pixels</p>
<ul>
<li><img src="../images/image-20220211211358340.png" alt="image-20220211211358340"></li>
</ul></li>
<li><p>the physical sensors can introduce non-linearity such as</p>
<p>distortion to the mapping.</p></li>
</ul></li>
</ul></li>
<li><p>Euclidian:</p>
<ul>
<li>projective transformation is non-linear in Euclidian Space</li>
<li>can not express in matrix form</li>
</ul></li>
<li><p>Homogeneous coordinate system</p>
<ul>
<li>add one dimension at the last dimension</li>
<li>projective transformation is linear</li>
<li>Projective transformation - Intrinsic matrix
<ul>
<li><img src="../images/image-20220211204920331.png" alt="image-20220211204920331"></li>
<li>Add camera Skewness: 5DoF</li>
<li><img src="../images/image-20220211204947805.png" alt="image-20220211204947805" style="zoom:100%;"></li>
</ul></li>
</ul></li>
</ul>
<h3 id="the-geometry-of-pinhole-camera">The geometry of pinhole camera</h3>
<ul>
<li><p>World reference system (Appendix A) - Extrin</p>
<ul>
<li><p>Translation in Homogeneous Coordinate: (2D) <img src="../images/image-20220211205416186.png" alt="image-20220211205416186" style="zoom:100%;"></p></li>
<li><p>R: rotation</p>
<ul>
<li>Euclidean: <img src="../images/image-20220105153342669.png" alt="image-20220105153342669"></li>
<li><img src="../images/image-20220105153349200.png" title="fig:" alt="image-20220105153349200"></li>
</ul></li>
<li><p>S: scaling in Homogenous Coordinate (2D), 1 DOF</p>
<figure>
<img src="../images/image-20220105153112079.png" alt="image-20220105153112079"><figcaption aria-hidden="true">image-20220105153112079</figcaption>
</figure>
<ul>
<li>3D rotation: 3 DOF. dimension: 3 (for 3D point; For 2d point, the dimension of R is 1) We can rotate around x, y, z axes <img src="../images/image-20220211205914054.png" alt="image-20220211205914054" style="zoom:100%;"></li>
</ul></li>
</ul></li>
<li><p>World reference system =&gt; Camera reference system</p>
<ul>
<li>R: totation</li>
<li>T: translation</li>
<li><img src="../images/image-20220105154312481.png" title="fig:" alt="image-20220105154312481"></li>
</ul></li>
<li><p>R, T extrinsic parameteres, only related to exteranl coordinate system</p>
<ul>
<li>K, intrinsic parameter: only about the camera system
<ul>
<li>5 dimensions of K: alpha, beta, Cx, Cy, theta</li>
</ul></li>
</ul></li>
<li><p>Projective transformation:</p>
<ul>
<li>M's dimension: 11
<ul>
<li>K =5, R=3, T=3 , total 11</li>
</ul></li>
</ul></li>
<li><p>Projection properties</p>
<ul>
<li>point to point</li>
<li>lines to lines
<ul>
<li>for fish cameras, it's not true. line to skews</li>
</ul></li>
<li>distant objects look smaller
<ul>
<li>length diviede by z (z is the depth/distance)</li>
<li>parallel lines intersect in the image at vanising point</li>
<li>Horizon line (vanishing line) is always a straight line</li>
</ul></li>
</ul></li>
<li><p>Canonical Projective transformation</p>
<ul>
<li><img src="../images/image-20220211211654433.png" alt="image-20220211211654433" style="zoom:100%;"></li>
</ul></li>
</ul>
<h2 id="lec3-camare-model2-camera-calibration">Lec3 Camare Model2 &amp; Camera Calibration</h2>
<ul>
<li>Recap:
<ul>
<li><img src="../images/image-20220110143737691.png" alt="image-20220110143737691" style="zoom:100%;"></li>
<li>Exercise: In homogeneous system: If the coordinate of world system and camera system is the same: [R T] = [I 0]
<ul>
<li>Assume caemra model as a focal length, zero skewness, no offset, and pixel are squrae:</li>
<li><img src="../images/image-20220110144419452.png" alt="image-20220110144419452" style="zoom:33%;">(no skew, no offset,)</li>
</ul></li>
<li>K, camera matrix:</li>
</ul></li>
<li>Weak perspective projection
<ul>
<li>remove non-linearity</li>
<li>When the relative scene depth is small conpared to its distance z_o form the camera</li>
<li>reference plane: can be assigned to any <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex" xmlns="http://www.w3.org/2000/svg" width="2.016ex" height="1.357ex" role="img" focusable="false" viewBox="0 -442 890.9 599.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mi" transform="translate(498,-150) scale(0.707)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g></g></g></g></svg></mjx-container></span></li>
<li>in Euclidan, the <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.605ex" xmlns="http://www.w3.org/2000/svg" width="2.863ex" height="2.322ex" role="img" focusable="false" viewBox="0 -759 1265.2 1026.4"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mo" transform="translate(839.5,363) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path></g><g data-mml-node="mi" transform="translate(675,-267.4) scale(0.707)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g></g></g></g></svg></mjx-container></span> simplified</li>
<li><img src="../images/image-20220211220731106.png" alt="image-20220211220731106" style="zoom:100%;"></li>
</ul></li>
<li>Orthographic projection:<img src="../images/image-20220211220814700.png" alt="image-20220211220814700" style="zoom:33%;">
<ul>
<li>the optical center is located at infinity</li>
</ul></li>
<li>Pros and cons:
<ul>
<li>weak perspective is much simpler, useful for recongnition</li>
<li>Pinhole perspective is acurate, useful for SLAM</li>
</ul></li>
<li><img src="../images/image-20220211221150964.png" alt="image-20220211221150964" style="zoom:100%;"></li>
</ul>
<h3 id="camera-calibration">Camera Calibration</h3>
<ul>
<li><p>Calibration:</p>
<ul>
<li>Estimate intrinsic and extrinsic parameteres from 1 or multiple images</li>
<li>Calibration rig: a typical rig is a cube. The corner is the original point of world reference system</li>
<li>11 unknow parameters, at least 6 corresponding point pairs (each point has 2 equations)
<ul>
<li><img src="../images/image-20220211221535704.png" alt="image-20220211221535704" style="zoom:100%;"></li>
</ul></li>
<li>P is homogenous coordinates</li>
<li>Solve by SVD:
<ul>
<li><img src="../images/image-20220211221628996.png" alt="image-20220211221628996" style="zoom:100%;"></li>
<li><img src="../images/image-20220212112214691.png" title="fig:" alt="image-20220212112214691"></li>
</ul></li>
<li>Degenerate case: all the point pairs should <strong>NOT</strong> belongs to a line or even a plane;
<ul>
<li>Points cannot lie on the intersection curve of two quadric surfaces</li>
</ul></li>
<li>Use <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.489ex" xmlns="http://www.w3.org/2000/svg" width="1.17ex" height="1.489ex" role="img" focusable="false" viewBox="0 -442 517 658"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D70C" d="M58 -216Q25 -216 23 -186Q23 -176 73 26T127 234Q143 289 182 341Q252 427 341 441Q343 441 349 441T359 442Q432 442 471 394T510 276Q510 219 486 165T425 74T345 13T266 -10H255H248Q197 -10 165 35L160 41L133 -71Q108 -168 104 -181T92 -202Q76 -216 58 -216ZM424 322Q424 359 407 382T357 405Q322 405 287 376T231 300Q217 269 193 170L176 102Q193 26 260 26Q298 26 334 62Q367 92 389 158T418 266T424 322Z"></path></g></g></g></svg></mjx-container></span> to correct scale issue (the matrix is up to scale)
<ul>
<li><img src="../images/image-20220110155330289.png" alt="image-20220110155330289" style="zoom:100%;"></li>
</ul></li>
</ul></li>
<li><p>Handling distortions</p>
<ul>
<li><p>start by solving linear problem (<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex" xmlns="http://www.w3.org/2000/svg" width="5.467ex" height="1.756ex" role="img" focusable="false" viewBox="0 -694 2416.6 776"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mo" transform="translate(860.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1916.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container></span>)</p></li>
<li><p>Another method: estimate m1 and m2 and ignore <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.027ex" xmlns="http://www.w3.org/2000/svg" width="1.319ex" height="1.597ex" role="img" focusable="false" viewBox="0 -694 583 706"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g></g></g></svg></mjx-container></span></p>
<ul>
<li>the slope is constant: u_i / v_i</li>
<li>first solve m1 and m2, then compute m3</li>
</ul></li>
<li><p>Radial Distortion:</p>
<ul>
<li><img src="../images/image-20220211223233825.png" alt="image-20220211223233825" style="zoom:100%;"></li>
<li>Not a linear system</li>
</ul></li>
<li><p>Solve: use slope</p>
<figure>
<img src="../images/image-20220212002132102.png" alt="image-20220212002132102"><figcaption aria-hidden="true">image-20220212002132102</figcaption>
</figure></li>
</ul></li>
</ul>
<h2 id="lec4-single-view-metrology">Lec4 Single View Metrology</h2>
<ul>
<li><p>Can I estimate P form the measurement p from a single image?</p>
<ul>
<li>We only know P is on the red line, but we do not know where P is.</li>
<li>Can not map from 2D to 3D</li>
</ul></li>
<li><p>Transformation in 2D</p>
<ul>
<li>Isometry: concate of rotation and translation
<ul>
<li>disscuse in homogenous space</li>
<li>preserve distance (areas)</li>
<li>Rotation + Transformation</li>
<li>DOF =3, degree of freedom (rotation:1, translation: 2)</li>
</ul></li>
<li>Similarity:
<ul>
<li>Unifom Scale, Rotation, translation <img src="../images/image-20220212101915711.png" alt="image-20220212101915711" style="zoom:100%;"></li>
<li>DOF = 4 (rotation:1, translation: 2, scale:1)</li>
<li>preserve the ratio of length</li>
</ul></li>
<li>Affine:
<ul>
<li><img src="../images/image-20220212101904927.png" title="fig:" alt="image-20220212101904927"></li>
<li><img src="../images/image-20220212102703295.png" alt="image-20220212102703295" style="zoom:33%;"></li>
<li>First rotate <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex" xmlns="http://www.w3.org/2000/svg" width="1.348ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 596 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D719" d="M409 688Q413 694 421 694H429H442Q448 688 448 686Q448 679 418 563Q411 535 404 504T392 458L388 442Q388 441 397 441T429 435T477 418Q521 397 550 357T579 260T548 151T471 65T374 11T279 -10H275L251 -105Q245 -128 238 -160Q230 -192 227 -198T215 -205H209Q189 -205 189 -198Q189 -193 211 -103L234 -11Q234 -10 226 -10Q221 -10 206 -8T161 6T107 36T62 89T43 171Q43 231 76 284T157 370T254 422T342 441Q347 441 348 445L378 567Q409 686 409 688ZM122 150Q122 116 134 91T167 53T203 35T237 27H244L337 404Q333 404 326 403T297 395T255 379T211 350T170 304Q152 276 137 237Q122 191 122 150ZM500 282Q500 320 484 347T444 385T405 400T381 404H378L332 217L284 29Q284 27 285 27Q293 27 317 33T357 47Q400 66 431 100T475 170T494 234T500 282Z"></path></g></g></g></svg></mjx-container></span>, then scale, then rotate back ,then rotate <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex" xmlns="http://www.w3.org/2000/svg" width="1.061ex" height="1.618ex" role="img" focusable="false" viewBox="0 -705 469 715"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g></svg></mjx-container></span></li>
<li>D: anisotropic scaling</li>
<li>Preserve parallel lines,</li>
<li>DOF: 6 (4 from matrix A, 2 from D)</li>
</ul></li>
<li>Projective transformation:
<ul>
<li><img src="../images/image-20220212102808916.png" alt="image-20220212102808916" style="zoom:100%;"></li>
<li>8 DOF ???</li>
</ul></li>
</ul></li>
</ul>
<h3 id="vanishing-points-and-lines">Vanishing points and lines</h3>
<ul>
<li><p>l: [a b c] (in 2D)</p></li>
<li><p>x belongs to l, <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex" xmlns="http://www.w3.org/2000/svg" width="7.431ex" height="2.09ex" role="img" focusable="false" viewBox="0 -841.7 3284.4 923.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,363) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g><g data-mml-node="mi" transform="translate(1152.8,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(1728.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(2784.4,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></svg></mjx-container></span></p></li>
<li><p>intersecting lines: <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex" xmlns="http://www.w3.org/2000/svg" width="9.053ex" height="1.903ex" role="img" focusable="false" viewBox="0 -759 4001.5 841"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(849.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1905.6,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(2425.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(3426,0)"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(331,363) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path></g></g></g></g></svg></mjx-container></span></p></li>
<li><p>Points at infinity: [x1, x2, 0]</p></li>
<li><p>lines in 2D plane</p>
<ul>
<li>lines infinity: [0 0 1]</li>
<li>Points and lines at infinity:
<ul>
<li>Projective transformation of a point at infinity <img src="../images/image-20220212104647721.png" alt="image-20220212104647721" style="zoom:100%;"></li>
<li>apply H for p_infinity:
<ul>
<li>is it a point at infinity? No</li>
<li>A is 2*2, v is a vector (1* 2 vector) to capture project ???, b does not matter</li>
<li>when v=0, it is a point at infinity [Px, Py, 0]</li>
</ul></li>
<li>Apply affine transformation: still a point at infinity</li>
</ul></li>
<li>Projective transforamtion of a line:
<ul>
<li>when H= HA, its a line at infinity</li>
</ul></li>
</ul></li>
<li><p>planes and points in 3D:</p>
<ul>
<li><span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.09ex" xmlns="http://www.w3.org/2000/svg" width="5.757ex" height="1.629ex" role="img" focusable="false" viewBox="0 -680 2544.6 720"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(849.8,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="mi" transform="translate(1794.6,0)"><path data-c="3A0" d="M128 619Q121 626 117 628T101 631T58 634H25V680H724V634H691Q651 633 640 631T622 619V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V634H232V348L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V619Z"></path></g></g></g></svg></mjx-container></span>, <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex" xmlns="http://www.w3.org/2000/svg" width="8.453ex" height="2.09ex" role="img" focusable="false" viewBox="0 -841.7 3736.4 923.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,363) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g><g data-mml-node="mi" transform="translate(1152.8,0)"><path data-c="3A0" d="M128 619Q121 626 117 628T101 631T58 634H25V680H724V634H691Q651 633 640 631T622 619V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V634H232V348L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V619Z"></path></g><g data-mml-node="mo" transform="translate(2180.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(3236.4,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></svg></mjx-container></span></li>
</ul></li>
<li><p>lines in 3D:</p>
<ul>
<li>Vanishing points
<ul>
<li><img src="../images/image-20220112151434270.png" alt="image-20220112151434270" style="zoom:100%;"> yes</li>
<li>M = K [R t] maps point in 3D into image, p = Mx</li>
<li>vanishing point is not at infinity</li>
</ul></li>
<li>v = Kd
<ul>
<li>K, camera matrix; d, diretion of the line in 3D respect to camera</li>
<li><img src="../images/image-20220212105253615.png" alt="image-20220212105253615" style="zoom:100%;"></li>
</ul></li>
</ul></li>
<li><p>horizontal lines: <img src="../images/image-20220212112533312.png" alt="image-20220212112533312" style="zoom:33%;"></p>
<ul>
<li><img src="../images/image-20220212112651930.png" alt="image-20220212112651930" style="zoom:100%;"></li>
<li>Are these two lines parallel?
<ul>
<li>Recognize the horizon line Measure if the 2 lines meet at the horizon if yes, these 2 lines are // in 3D</li>
<li>Need to know the intersect point belong to horizontal</li>
<li>originate at the same vanishing point -&gt; parallel</li>
</ul></li>
</ul></li>
<li><p>Vanishing points and planes:</p>
<ul>
<li>n, the normal of plane <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0" xmlns="http://www.w3.org/2000/svg" width="1.697ex" height="1.538ex" role="img" focusable="false" viewBox="0 -680 750 680"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="3A0" d="M128 619Q121 626 117 628T101 631T58 634H25V680H724V634H691Q651 633 640 631T622 619V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V634H232V348L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V619Z"></path></g></g></g></svg></mjx-container></span>, calculate the normal in camera system</li>
<li><img src="../images/image-20220212112744422.png" alt="image-20220212112744422" style="zoom:30%;"></li>
<li>A set of 2 or more lines at infinity defines the plane at infinity <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.8ex" xmlns="http://www.w3.org/2000/svg" width="5.842ex" height="2.338ex" role="img" focusable="false" viewBox="0 -680 2582.4 1033.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="3A0" d="M128 619Q121 626 117 628T101 631T58 634H25V680H724V634H691Q651 633 640 631T622 619V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V634H232V348L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V619Z"></path></g><g data-mml-node="TeXAtom" transform="translate(783,-176.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext" fill="red" stroke="red"><path data-c="5C" d="M56 731Q56 740 62 745T75 750Q85 750 92 740Q96 733 270 255T444 -231Q444 -239 438 -244T424 -250Q414 -250 407 -240Q404 -236 230 242T56 731Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(500,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(778,0)"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1334,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1640,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1918,0)"></path></g></g></g></g></g></svg></mjx-container></span></li>
</ul></li>
<li><p>Angle between 2 vanishing points</p>
<ul>
<li><img src="../images/image-20220212113141699.png" alt="image-20220212113141699" style="zoom:100%;"></li>
<li>Calculate K: <img src="../images/image-20220212113506458.png" alt="image-20220212113506458" style="zoom:100%;"></li>
<li>useful to calibrate the camera; estimate the geometry of the 3D world.</li>
</ul></li>
</ul>
<h3 id="estimating-geometry-from-a-single-image">Estimating geometry from a single image</h3>
<ul>
<li><p>A Single View Metrology Example</p>
<ul>
<li>we can measure v1, v2, v3 in image <img src="../images/image-20220212113839375.png" alt="image-20220212113839375" style="zoom:100%;">
<ul>
<li>using Cholesky factorization to solve K</li>
</ul></li>
<li>The equations are not sufficient for K, since K has 5 DOF</li>
<li>the angle of each pair of plains is 90 (knowledge). If we do not have the knowledge, we can have ML methods</li>
<li>with simplified camera model, we can calculate <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0" xmlns="http://www.w3.org/2000/svg" width="0.036ex" height="0.036ex" role="img" focusable="false" viewBox="0 0 16 16"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"></g></g></svg></mjx-container> using 3 points</li>
<li>normal n is in the camera coordinate system
<ul>
<li>calculate normal n =&gt; reconstruction from single view</li>
<li>the actual scale of the scene is NOT recovered</li>
</ul></li>
</ul></li>
</ul>
<h2 id="lec5-epipolar-geometry">Lec5 Epipolar Geometry</h2>
<ul>
<li><p>Epipolar Genometry = multi-view geometry</p></li>
<li><p><img src="../images/image-20220212114844274.png" alt="image-20220212114844274" style="zoom:100%;"></p>
<ul>
<li>Intrinsic ambiguity of the mapping from 3D to image (2D)</li>
</ul></li>
<li><p>Two eyes help - Triangulation</p>
<ul>
<li>cross product of two line =&gt; intersection point, in homogenous system</li>
<li>If there are some noise, the lines won't intersect
<ul>
<li>find minimizes: <img src="../images/image-20220212114955631.png" alt="image-20220212114955631" style="zoom:100%;"></li>
</ul></li>
</ul></li>
<li><p>Triangulation:</p>
<ul>
<li>P* is the estimation of actual P (P in 3D)</li>
<li>Do not need to calculate the line in 3D, which is hard to do</li>
</ul></li>
<li><p>Multi-view genometry</p>
<ul>
<li><p>in this lecture, we suppose the corresponding p and p' is given <img src="../images/image-20220212115448161.png" alt="image-20220212115448161" style="zoom:100%;"></p></li>
<li><p>the line connect O1 and O2 is called baseline</p></li>
<li><p>Epipolar lines: blue lines, p'e' and pe</p></li>
<li><p>Epipoles: e, e'</p>
<ul>
<li><p>= intersections of baseline with image planes</p>
<p>= projections of the other camera center</p></li>
</ul></li>
<li><p>Can we know where is p'?</p>
<ul>
<li>p' must be on epipolar line</li>
<li>p' is no longer on the arbirarly position of the line</li>
</ul></li>
<li><p>camera is canonical:</p>
<ul>
<li>K is identity matrix (K is the camera intrincs)</li>
</ul></li>
</ul></li>
<li><p>Epipolar Constraint:</p>
<ul>
<li>Essential Matrix</li>
<li><img src="../images/image-20220212120233573.png" alt="image-20220212120233573" style="zoom:100%;">
<ul>
<li>p' is at the second camera reference system</li>
</ul></li>
<li><img src="../images/image-20220212120035219.png" alt="image-20220212120035219" style="zoom:100%;"></li>
<li><img src="../images/image-20220212121545351.png" alt="image-20220212121545351" style="zoom:100%;">
<ul>
<li><span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex" xmlns="http://www.w3.org/2000/svg" width="1.302ex" height="1.742ex" role="img" focusable="false" viewBox="0 -759 575.5 770"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(331,363) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path></g></g></g></g></svg></mjx-container></span> is defined by p' and the base line, so <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex" xmlns="http://www.w3.org/2000/svg" width="0.674ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 298 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g></svg></mjx-container></span> must be associate with p'</li>
<li>E has 5 DOF: <strong>E is up to scale</strong>, and T has 3 DOF, and R has 3 DOF</li>
</ul></li>
</ul></li>
<li><p>Cross product to matrix:</p>
<ul>
<li><img src="../images/image-20220212120401005.png" title="fig:" alt="image-20220212120401005"></li>
</ul></li>
<li><p>Fundamental Matrix:</p>
<ul>
<li>Esstential matrix is derived using canonical cameras assumption. Fundamental matrix does NOT have this assumption</li>
<li><img src="../images/image-20220212122017733.png" title="fig:" alt="image-20220212122017733"></li>
<li><img src="../images/image-20220212122025247.png" alt="image-20220212122025247" style="zoom:100%;"></li>
<li>can also be calcualted according to just observations</li>
<li>F gives constrains on how the scene changes under view point transformations</li>
</ul></li>
<li><p>Estimating F</p>
<ul>
<li>8 points algorithm:
<ul>
<li>Step1: <img src="../images/image-20220212122446170.png" alt="image-20220212122446170" style="zoom:100%;"></li>
<li>Step2: <img src="../images/image-20220212122547013.png" alt="image-20220212122547013" style="zoom:100%;"></li>
</ul></li>
<li>What is the problem of 8-points algorithms
<ul>
<li>uv in matrix W may be very large,some item in matrix W can be very small</li>
<li>Highly un-balanced (not well conditioned)</li>
<li>Values of W must have similar magnitude</li>
<li>This creates problems during the SVD decomposition</li>
</ul></li>
</ul></li>
<li><p>Normalized 8 points</p>
<ul>
<li>Mean square distance of the image points from origin is ~2 pixels</li>
<li><img src="../images/image-20220212122727286.png" alt="image-20220212122727286" style="zoom:100%;"></li>
</ul></li>
</ul>
<h2 id="lec6-stereo-systems-multi-view-geometry">Lec6 Stereo Systems/ Multi-view Geometry</h2>
<ul>
<li><p>Essential Matrix</p>
<ul>
<li>camera are caronicol</li>
<li>l = Ep</li>
<li>pEp' = 0</li>
<li>E = [Tx] R</li>
</ul></li>
<li><p>Fundamental Matrix</p>
<ul>
<li><img src="../images/image-20220212143933172.png" alt="image-20220212143933172" style="zoom:33%;"></li>
</ul></li>
<li><p>Parallel image planes:</p>
<ul>
<li><img src="../images/image-20220212123038943.png" title="fig:" alt="image-20220212123038943"></li>
<li><img src="../images/image-20220212123055035.png" alt="image-20220212123055035" style="zoom:100%;"></li>
<li><img src="../images/image-20220212123110011.png" title="fig:" alt="image-20220212123110011"></li>
<li><img src="../images/image-20220212123123502.png" title="fig:" alt="image-20220212123123502"></li>
<li><img src="../images/image-20220212123138838.png" title="fig:" alt="image-20220212123138838"></li>
<li>Rectification: making two images "parallel"
<ul>
<li>make triangulation easy</li>
<li>rectification is a homography (projective transformation)</li>
</ul></li>
<li>Application: view morphing
<ul>
<li>New views can be synthesized by linear interpolation</li>
</ul></li>
</ul></li>
<li><p>Parallel image planes</p>
<ul>
<li>O1-xyz are attached to the camera</li>
<li>p and p' <strong>share same v coordinates</strong> (parallel)</li>
<li>Rectification: make any two images parallel, homographic transformation H
<ul>
<li>homographic transformation ??: transfrom a plan to another plane<br>
</li>
</ul></li>
<li>Inteplate view between two parallel images -&gt; get different views</li>
</ul></li>
<li><p>Why are parallel images important?</p>
<ul>
<li><p>Makes triangulation easy - point triangulation</p>
<ul>
<li><p>disparity = p_u - p_u', propotional to B*f/z</p></li>
<li><p><img src="../images/image-20220124120750124.png" alt="image-20220124120750124" style="zoom:33%;"></p></li>
<li><p>the black points are not shadows, are occlusions(do not how to decided)</p></li>
</ul></li>
<li><p>Make the <strong>correspondence problem</strong> easier</p>
<ul>
<li><p>Correspondence problem</p>
<ul>
<li>p belongs to l = Fp' =&gt; 1 dimensional search problem</li>
<li>What's the problem?
<ul>
<li>different lighting?</li>
</ul></li>
</ul></li>
<li><p>Window-based correlation Methods</p>
<ul>
<li><p><img src="../images/image-20220212150103993.png" alt="image-20220212150103993" style="zoom:100%;"></p></li>
<li><p>nomalize: Changes in the mean and the variance of intensity values in corresponding windows!</p>
<ul>
<li><img src="../images/image-20220212150242398.png" alt="image-20220212150242398" style="zoom:100%;"></li>
</ul></li>
<li><p>Effect of the window size</p>
<ul>
<li><p>Smaller window</p>
<p>More detail</p>
<p>More noise</p></li>
<li><p>Larger window</p>
<p>Smoother disparity maps</p>
<p>Less prone to noise</p></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Issues of Corresponence problem:</p>
<ul>
<li>Fore shortening effect</li>
<li>Oclusions</li>
<li>To reduce the effect of foreshortening and occlusions, it is desirable to have small B / z ratio!</li>
<li>However, when B/z is small, small errors in measurements imply large error in estimating depth</li>
</ul></li>
<li><p>Base line trade-off:</p>
<ul>
<li>Small errors in measure ments imply large error in estimating depth; small B/z ratio brings large triangulation error when measurement error <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.576ex" xmlns="http://www.w3.org/2000/svg" width="2.227ex" height="2.294ex" role="img" focusable="false" viewBox="0 -759 984.5 1013.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(605,363) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path></g><g data-mml-node="mi" transform="translate(605,-247) scale(0.707)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g></g></g></g></svg></mjx-container></span></li>
<li><img src="../images/image-20220212150557175.png" title="fig:" alt="image-20220212150557175"></li>
</ul></li>
<li><p>Non-local constraints to help enforce the correspondence</p>
<ul>
<li><p>Difficult:</p>
<p>- Occlusions - Fore shortening - Baseline trade-off - Homogeneous regions</p>
<p>- Repetitive patterns</p></li>
<li><p>uniqueness: For any point in one image, there should be at most one matching point in the other image</p></li>
<li><p>Ordering: Corresponding points should be in the same order in both views</p></li>
<li><p>Smoothness: Disparity is typically a smooth function of x (except in occluding boundaries)</p></li>
</ul></li>
<li><p>Multi-view Problem</p>
<ul>
<li>Structure from motion problem (SFM): locolize the location of camera for each image; build 3D points</li>
</ul></li>
<li><p>SFM:</p>
<ul>
<li>Affine SFM: Affine structure from motion
<ul>
<li><img src="../images/image-20220212151024382.png" title="fig:" alt="image-20220212151024382"></li>
<li><img src="../images/image-20220212151034078.png" title="fig:" alt="image-20220212151034078"></li>
</ul></li>
<li>Two approaches:
<ul>
<li>Algebraic approach (affine epipolar geometry; estimate F; cameras; points)</li>
<li>Factorization method</li>
</ul></li>
</ul></li>
</ul>
<h2 id="lec7-multi-view-geometry">Lec7 Multi-view Geometry</h2>
<h3 id="affine-sfm">Affine SFM</h3>
<ul>
<li><p>Affine Structure-from-Motion Problem</p>
<ul>
<li><img src="../images/image-20220212151851227.png" alt="image-20220212151851227" style="zoom:100%;"></li>
</ul></li>
<li><p>Factorization method</p>
<ul>
<li>centering each image.</li>
<li>Centering: subtract the centroid of the image points</li>
<li><img src="../images/image-20220212152314427.png" alt="image-20220212152314427" style="zoom:100%;"></li>
<li><img src="../images/image-20220212152321141.png" alt="image-20220212152321141" style="zoom:100%;"></li>
<li><img src="../images/image-20220212152410400.png" alt="image-20220212152410400" style="zoom:100%;"></li>
<li>SVD decomposition, and get combination of u and w is Motion(M), v is</li>
<li><img src="../images/image-20220212152523114.png" alt="image-20220212152523114" style="zoom:100%;">
<ul>
<li>Noises</li>
<li>Affine approximation</li>
</ul></li>
</ul></li>
<li><p>Problems: Affine Ambiguity</p>
<ul>
<li><p>The decomposition is not unique. We get the same <strong>D</strong> by applying the transformations: H is arbitrary 3*3 matrix describing an affine transformation</p>
<p><strong>M* = M H </strong></p>
<p><strong>S* = H</strong> <strong>^-1 S</strong></p></li>
<li><p>Need additional constraints</p></li>
<li><p>The scene is determined by the images only up a <strong>similarity</strong></p>
<p><strong>transformation</strong> (rotation, translation and scaling)</p>
<ul>
<li>The ambiguity exists even for (intrinsically) calibrated cameras</li>
<li>For <strong>calibrated cameras</strong>, the similarity ambiguity is the only ambiguity</li>
</ul></li>
</ul></li>
</ul>
<h3 id="perspective-sfm">Perspective SFM</h3>
<ul>
<li><p>From the mxn observations <strong>x_</strong>ij, estimate:</p>
<p><em>m</em> projection matrices <strong>M</strong>= motion <em>i</em></p>
<p><em>n</em> 3D points <strong>X</strong>_j = structure</p></li>
<li><p>Perspective SFM</p>
<ul>
<li><img src="../images/image-20220212154209222.png" title="fig:" alt="image-20220212154209222"></li>
<li>If the cameras are <strong>not calibrated</strong>, cameras and points can only be recovered up to a 4x4 projective (where the 4x4 projective is defined up to scale)</li>
<li>projective ambiguity</li>
<li>2mn equations in <strong>11m+3n – 15</strong> unknowns</li>
</ul></li>
<li><p>Methods:</p>
<ul>
<li><p>algebraic approach</p></li>
<li><p>Factorization method - Affine SFM</p></li>
<li><p>Bundle adjustment</p></li>
</ul></li>
<li><p>Algebraic Approach:</p>
<ul>
<li><p>Compute the fundamental matrix F from two views</p>
<ul>
<li>at least 8 point correspondences, compute F</li>
</ul></li>
<li><p>Use F to estimate projective cameras</p>
<ul>
<li><p><img src="../images/image-20220212155311444.png" alt="image-20220212155311444" style="zoom:100%;"></p></li>
<li><p><img src="../images/image-20220212155709506.png" alt="image-20220212155709506"> <img src="../images/image-20220212155746329.png" alt="image-20220212155746329"></p></li>
<li><p><img src="../images/image-20220212160101234.png" alt="image-20220212160101234"> <img src="../images/image-20220212160111700.png" alt="image-20220212160111700"></p></li>
<li><p>b is an epipole!</p></li>
</ul></li>
<li><p>Use these cameras to <strong>triangulate</strong> and estimate points in 3D</p>
<ul>
<li>3D points can be computed from camera matrices via SVD</li>
</ul></li>
</ul></li>
<li><p>Algebraic Approach: the N-views case</p>
<ul>
<li>Pairwise solutions may be combined together using <em>bundle adjustment</em></li>
</ul></li>
<li><p>Bundle adjustment</p>
<ul>
<li></li>
<li><p>limitations of previous methods:</p>
<ul>
<li><p><strong>Factorization methods</strong> assume all points are visible. This not true if:</p>
<p>• occlusions occur • failure in establishing correspondences</p></li>
<li><p><strong>Algebraic methods</strong> work with 2 views</p></li>
</ul></li>
<li><figure>
<img src="../images/image-20220212164200706.png" alt="image-20220212164200706"><figcaption aria-hidden="true">image-20220212164200706</figcaption>
</figure></li>
<li><p>Use Levenberge-Marquardt Algorithm to minimize</p></li>
<li><p>Advantages:</p>
<ul>
<li>handle large number of views</li>
<li>Handle missing data</li>
</ul></li>
</ul></li>
<li><p>Self-calibartion</p>
<ul>
<li><p>the problem of <u>recovering the metric reconstruction</u> from the perspective (or affine) reconstruction</p></li>
<li><p>Several approaches:</p>
<ul>
<li>- Use single-view metrology constraints (lecture 4)</li>
<li>- Direct approach (Kruppa Eqs) for 2 views</li>
<li>- Algebraic approach</li>
<li>- Stratified approach</li>
</ul></li>
<li><p>Inject information about the camera during the bundle adjustment optimization</p></li>
<li><p>For calibrated cameras, the similarity ambiguity is the only ambiguity</p></li>
<li><p><img src="../images/image-20220212165138627.png" alt="image-20220212165138627"> Projective reconstruction =&gt; affine reconstruction (up to affinity) =&gt; similarity reconstruction (up to scale)</p></li>
</ul></li>
<li><p><img src="../images/image-20220212164744303.png" alt="image-20220212164744303" style="zoom:100%;"></p></li>
</ul>
<h2 id="lec8-active-stereo-volumetric-stereo">Lec8 Active stereo &amp; Volumetric stereo</h2>
<ul>
<li><p>Traditional Stereo</p>
<ul>
<li>Main problem: need to find correspondence</li>
</ul></li>
<li><p>Replace one of the two cameras by a projector</p>
<ul>
<li>Projector geometry calibrated</li>
<li>What’s the advantage of having the projector? Correspondence problem solved!</li>
<li>Projector and camera are parallel</li>
</ul></li>
<li><p>Laser Scanning:</p>
<ul>
<li>Optical triangulation</li>
<li>Project a single stripe of laser light</li>
<li>Scan it across the surface of the object</li>
<li>This is a very precise version of structured light scanning</li>
<li>Cons:
<ul>
<li>slow</li>
<li>Cannot capture deformations in time</li>
</ul></li>
</ul></li>
<li><p>Active stereo</p>
<ul>
<li>- Dense reconstruction - Correspondence problem again - Get around it by using color codes</li>
</ul></li>
<li><p>Depth sensing</p>
<ul>
<li>Infrared laser projector combined with a CMOS sensor</li>
</ul></li>
<li><p>Volumetric stereo:</p>
<ul>
<li><img src="../images/image-20220212185331476.png" alt="image-20220212185331476" style="zoom:100%;"></li>
<li><img src="../images/image-20220212185346967.png" alt="image-20220212185346967" style="zoom:100%;"></li>
</ul></li>
<li><p>Contours / silhouettes</p>
<ul>
<li><p>silhouette is defined as the area enclosed by the apparent contours</p></li>
<li><p>Using contours/silhouettes in volumetric stereo, also called</p>
<p><strong>space carving</strong></p></li>
<li><p>How to use Contours: visual hull / visual corn</p></li>
<li><p><strong>Consistency:</strong> A voxel must be projected into a silhouette in each image</p></li>
<li><p>Space carving complexity: O(n3)</p>
<ul>
<li>use Octrees to speedup</li>
<li><img src="../images/image-20220212192925343.png" alt="image-20220212192925343" style="zoom:100%;"></li>
</ul></li>
<li><p>pros and cons:</p>
<ul>
<li>Robust and simple</li>
<li>No need to solve for correspondences</li>
<li>Produce conservative estimates</li>
<li>cons: Accuracy function of number of views</li>
<li>cons: Concavities are not modeled</li>
</ul></li>
</ul></li>
<li><p>Space Carving:</p>
<ul>
<li>use contours / silhouettes</li>
</ul></li>
<li><p>Shadow Carving</p>
<ul>
<li><p>Self-shadows are visual cues for shape recovery</p></li>
<li><p>Camera + array of lights</p></li>
<li><p><img src="../images/image-20220212194138419.png" alt="image-20220212194138419" style="zoom:100%;"></p></li>
<li><p>Summary:</p>
<ul>
<li>Produces a <strong>conservative</strong> volume estimate</li>
<li>Accuracy depending on view point and light source number</li>
<li>Limitations with reflective &amp; low albedo regions</li>
</ul></li>
</ul></li>
<li><p>Voxel Coloring: use color as consistency test</p>
<ul>
<li>non-unique: multiple consistent scenes
<ul>
<li>how to fix: need to use a visibility constraint</li>
<li>if a voxel in two image are consistent, mark the voxel "in"</li>
</ul></li>
<li>A Critical Assumption: Lambertian Surfaces
<ul>
<li>color is not related to the view point</li>
</ul></li>
<li>Photo consistency test
<ul>
<li><img src="../images/image-20220212200536096.png" alt="image-20220212200536096" style="zoom:100%;"></li>
</ul></li>
<li>Good things – Model intrinsic scene colors and texture – No assumptions on scene topology</li>
<li>Limitations: – Constrained camera positions – Lambertian assumption</li>
</ul></li>
</ul>
<h2 id="lec9-fitting-and-matching">Lec9 Fitting and Matching</h2>
<ul>
<li><p>Fitting</p>
<ul>
<li>Choose a <strong>parametric</strong> model to fit a certain quantity from data</li>
<li>Estimatemodelparameters</li>
<li>Critical issues:
<ul>
<li>noisy data</li>
<li>outliers</li>
<li>missing data (occlusion)</li>
<li>Intra-class variation</li>
</ul></li>
<li>Techniques:
<ul>
<li>least square methods</li>
<li>RANSAC</li>
<li>Hough Transform</li>
<li>EM (Expectation Maximization)</li>
</ul></li>
</ul></li>
<li><p>Least square methods:</p>
<ul>
<li><img src="../images/image-20220212211821101.png" title="fig:" alt="image-20220212211821101"></li>
<li>h: the parameter of the model</li>
<li>using calculus to solve</li>
<li>Issue: fails completely for vertical lines, m is infinity</li>
<li>Another way:
<ul>
<li><img src="../images/image-20220212212138476.png" title="fig:" alt="image-20220212212138476"></li>
<li><img src="../images/image-20220212212146645.png" title="fig:" alt="image-20220212212146645">
<ul>
<li>rank deficient means a lot of solutions, not unique. Need an optimal solution</li>
<li>using SVD to solve: last column of V correspond to the smallest singluar value</li>
</ul></li>
<li>Limitations: Robustness to noise is not good</li>
</ul></li>
</ul></li>
<li><p>RANSAC (RANdom SAmple Consensus)</p>
<ul>
<li><p>Data elements are used to vote for one (or multiple) models</p></li>
<li><p>verify for a given model, see whether a good fit</p></li>
<li><p><strong>Assumption 1</strong>: Noisy data points will not vote consistently for any single model (“few” outliers)</p></li>
<li><p><strong>Assumption 2</strong>: There are enough data points to agree on a good model (“few” missing data)</p></li>
<li><p><span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0" xmlns="http://www.w3.org/2000/svg" width="1.697ex" height="1.538ex" role="img" focusable="false" viewBox="0 -680 750 680"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="3A0" d="M128 619Q121 626 117 628T101 631T58 634H25V680H724V634H691Q651 633 640 631T622 619V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V634H232V348L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V619Z"></path></g></g></g></svg></mjx-container></span> is a fuction, P is a set of all data, I is a set of inlier, O is a set of Outlier</p></li>
<li><p>Solve for <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0" xmlns="http://www.w3.org/2000/svg" width="1.697ex" height="1.538ex" role="img" focusable="false" viewBox="0 -680 750 680"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="3A0" d="M128 619Q121 626 117 628T101 631T58 634H25V680H724V634H691Q651 633 640 631T622 619V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V634H232V348L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V619Z"></path></g></g></g></svg></mjx-container></span>, residual is below threshold <img src="../images/image-20220212214051809.png" alt="image-20220212214051809" style="zoom:100%;"></p>
<ul>
<li>need to decided threshold before run RANSAC</li>
</ul></li>
<li><p>Algorithm: <img src="../images/image-20220212214407201.png" alt="image-20220212214407201" style="zoom:100%;"></p></li>
<li><p>How many samples?</p>
<ul>
<li><p><strong>N samples are sufficient</strong></p></li>
<li><p>N = number of samples required to ensure, with a probability p, that at least one random sample produces an inlier set that is free from “real” outliers</p>
<ul>
<li>want to get rid of outliers</li>
</ul></li>
<li><p>number of sample is a function of <em>s</em> and <em>e</em>:</p>
<ul>
<li><p><em>e =</em> outlier ratio (make a guess)</p></li>
<li><p>s = minimum number of data points needed to fit the model (depend on number of parameters of model)</p></li>
</ul></li>
<li><p>Usually, <em>p</em>=0.99</p>
<figure>
<img src="../images/image-20220212215528836.png" alt="image-20220212215528836"><figcaption aria-hidden="true">image-20220212215528836</figcaption>
</figure></li>
</ul></li>
<li><p>Good:</p>
<p>• Simple and easily implementable • Successful in different contexts</p></li>
<li><p>Bad:</p>
<p>• Many parameters to tune • Trade-off accuracy-vs-time • Cannot be used if ratio inliers/outliers is too small</p></li>
</ul></li>
<li><p>Hough transforms</p>
<ul>
<li><p><img src="../images/image-20220212233706214.png" alt="image-20220212233706214" style="zoom:100%;"></p></li>
<li><p>all points on x-y plane y =m'x + n' , result a intersection point in m-n plane</p></li>
<li><p>Issue: The parameter space [m,n] is unbounded...</p>
<ul>
<li>Use a polar representation for the parameter space</li>
</ul></li>
<li><p>How to compute the intersection point? In presence of noise!</p>
<ul>
<li>IDEA: introduce a grid a count intersection points in each cell</li>
<li>Issue: Grid size needs to be adjusted</li>
</ul></li>
<li><p>Good:</p>
<p>• All points are processed independently, so can cope with occlusion/outliers</p>
<p>• Some robustness to noise: noise points unlikely to contribute consistently to any single cell</p></li>
<li><p>Bad:</p>
<p>• Spurious peaks due to uniform noise</p>
<p>• Trade-off noise-grid size (hard to find sweet point)</p>
<p>• Doesn’t handle well high dimensional models</p></li>
</ul></li>
<li><p>Generalized Hough Transform</p>
<ul>
<li>Parameterize a shape by measuring the location of its parts and shape centroid</li>
<li>Given a set of measurements, cast a vote in the Hough (parameter) space</li>
</ul></li>
<li><p>Multi-model Fitting</p>
<ul>
<li>Incremental line fitting</li>
<li>Hough transform</li>
</ul></li>
<li><p>Fitting helps matching</p>
<ul>
<li><img src="../images/image-20220212235113934.png" title="fig:" alt="image-20220212235113934"></li>
<li>Fitting an homography H (by RANSAC) mapping features from images 1 to 2</li>
<li>Bad matches will be labeled as outliers (hence rejected)!</li>
<li>Application: Panoramas</li>
</ul></li>
</ul>
<h2 id="lec10-representations-and-representation-learning">Lec10 Representations and Representation Learning</h2>
<ul>
<li><p>What is a state? What is a representation?</p>
<ul>
<li>Markov Model</li>
<li>State</li>
<li>control input</li>
<li><img src="../images/image-20220213002134974.png" alt="image-20220213002134974" style="zoom:100%;"></li>
<li>State is partial or can not observable
<ul>
<li>​ <img src="../images/image-20220213002241264.png" alt="image-20220213002241264"></li>
</ul></li>
<li>Partially observable Markov decision process: Infer state x using observation z</li>
<li>eg: 6DOF estimation</li>
<li>Use observation go back to the state:
<ul>
<li>Method1, eg: generative observation Model
<ul>
<li>generative model: 𝑧 = h(𝑥)</li>
<li>The relationship between x and z: 𝑃(𝑧|𝑥)</li>
<li>generate z from x, then compare with ground truth</li>
</ul></li>
<li>Method2, eg: Discriminative observation Model
<ul>
<li>Discriminative Model: 𝑧 = 𝑔(𝐼)</li>
<li>The relationship between x and z: 𝑧 = 𝑥 = h(𝑥)</li>
<li>h is filtering, take accumulative information from other frames</li>
<li>Traking by decision</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Representation in Computer Vision</p></li>
<li><p>Requirements for Good Representations</p>
<ul>
<li>Compact (minimal)</li>
<li>Explanatory (sufficient)</li>
<li>Disentangled (independent factors)</li>
<li>Hierarchical (feature reuse)</li>
<li>Makes subsequent problem easier</li>
</ul></li>
<li><p>object =&gt; representation =&gt; Mathematical Model(eg, classifier) =&gt; different types</p></li>
<li><p>Traditional Components:</p>
<ul>
<li>Color Histograms</li>
<li>Model based Shapes</li>
<li>Deformable Part based Models (DPM)</li>
<li>Histogram of Gradients (HOG)</li>
</ul></li>
<li><p>undertanding representations through low-dimensional embeddings</p>
<ul>
<li>t-SNE</li>
</ul></li>
<li><p>nsupervised Representation Learning</p>
<ul>
<li>Auto-endcoder
<ul>
<li>Reconstruction loss to minimize by finding optimal F</li>
</ul></li>
</ul></li>
<li><p>Representation Learning:</p>
<ul>
<li><p><strong>Reinforcement Learning</strong> (Cherry) Predicting a scalar reward given once in a while A few bits for some samples</p></li>
<li><p><strong>Supervised Learning</strong> (Chocolate Coat)</p>
<p>Predicting category or vector of scalars per input as provided by human labels. 10-10k bits per sample</p></li>
<li><p><strong>Unsupervised / Self-Supervised Learning</strong> (Cake)</p>
<p>Predicting parts of observed input or predicting future observations or events Millions of bits per sample</p></li>
</ul></li>
</ul>
<h3 id="summary">Summary</h3>
<ul>
<li><strong>State:</strong> Quantity that describes the most important aspect of a dynamical system at time t</li>
<li><strong>Representation:</strong> data format of input or output including a low-dimensional representation of sensor data</li>
<li>Learned versus interpretable representations</li>
<li>Visualize learned representations</li>
<li>How to learn representations?
<ul>
<li>Supervised</li>
<li>Unsupervised</li>
<li>Self-supervised</li>
</ul></li>
</ul>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><a class="button is-default" href="/blog/posts/30dfa412" title="CS245-Notes"><i class="iconfont icon-prev mr-2 has-text-grey"></i><span class="has-text-weight-semibold">Previous: CS245-Notes</span></a><a class="button is-default" href="/blog/posts/1a89ccec" title="System R"><span class="has-text-weight-semibold">Next: System R</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="Haojen/Claudia-theme-blog" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/wwwjn"><i class="iconfont icon-github"></i></a><!-- Ins--><!-- RSS--><!-- 知乎--><!-- 领英--><a title="linkedin" target="_blank" rel="noopener nofollow" href="//www.linkedin.com/in/wangjiani"><i class="iconfont icon-linkedin"></i></a><!-- 脸书--></section><p><span>Copyright ©</span><span> Jiani Wang 2022</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/blog/js/post.js"></script></body></html>