<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>CS245-Notes</title><meta name="description" content="Keep Learning"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/blog/images/favicon.png"><link rel="stylesheet" href="/blog/style/common/bulma.css"><link rel="stylesheet" href="/blog/style/base.css"><link rel="stylesheet" href="/blog/style/common/helper.css"><script src="/blog/js/common.js"></script><link rel="stylesheet" href="/blog/style/post.css"><link rel="stylesheet" href="/blog/style/themes/highlight-theme-light.css"><script src="/blog/js/highlight.pack.js"></script><meta name="description" content="CS245 Lecture Notes
Jiani Wang (jianiw@stanford.edu)
[TOC]
Lec1 Introdution

Why study data-intensive system

Most important computer application must manage, update and query datasets
more important with AI

What are Data-Intensive Systems

Relational databases (MySQL, Oracle)
Many system facing similar concerns

Typical Challenges:

Reliability
Concurren.."><meta name="generator" content="Hexo 5.4.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/blog/">Jiani Wang's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">CS245-Notes</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Click back to the top</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/blog/about">About</a></h3><h3 class="is-inline-block"><a href="/blog/">Blog</a></h3><h3 class="is-inline-block"><a href="/blog/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/blog/about">About</a></h3><h3 class="is-inline-block"><a href="/blog/">Blog</a></h3><h3 class="is-inline-block"><a href="/blog/archives">Archives</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#cs245-lecture-notes"><span class="toc-text">CS245 Lecture Notes</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#lec1-introdution"><span class="toc-text">Lec1 Introdution</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec2-system-r"><span class="toc-text">Lec2 System R</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#system-r"><span class="toc-text">System R</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#relational-dbms-architecture"><span class="toc-text">Relational DBMS architecture</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec3-database-system-architecture-2-storage"><span class="toc-text">Lec3 Database System Architecture 2 &amp; Storage</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#alternative-dbms-structures"><span class="toc-text">Alternative DBMS structures</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#storage-storage-hardware"><span class="toc-text">Storage: Storage Hardware</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec4-data-storage-formats"><span class="toc-text">Lec4 Data Storage Formats</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#record-encoding"><span class="toc-text">Record encoding</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#collection-storage"><span class="toc-text">Collection Storage</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec5-storage-foramt-c-store-paper"><span class="toc-text">Lec5 Storage Foramt C-Store paper</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#c-store-paper"><span class="toc-text">C-Store Paper</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#index"><span class="toc-text">Index</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec6-query-execution"><span class="toc-text">Lec6 Query Execution</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#hash-table"><span class="toc-text">Hash table</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#multiple-key"><span class="toc-text">Multiple key</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#query-execution"><span class="toc-text">Query Execution</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec7-query-optimization"><span class="toc-text">Lec7 Query Optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#rule-based-optimization"><span class="toc-text">Rule-based optimization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#data-statistics"><span class="toc-text">Data Statistics</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec8-query-optimization2"><span class="toc-text">Lec8 Query Optimization2</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#cost-models"><span class="toc-text">Cost models</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cost-based-plan-selection"><span class="toc-text">Cost-based plan selection</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-sql"><span class="toc-text">Spark SQL</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec9-tanscations-and-failure-recovery1"><span class="toc-text">Lec9 Tanscations and Failure Recovery1</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-sql-wrap-up"><span class="toc-text">Spark SQL Wrap-up</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#defining-correctness"><span class="toc-text">Defining Correctness</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#transcation-model"><span class="toc-text">Transcation model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hardware-failures"><span class="toc-text">Hardware failures</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#recovery-with-logs"><span class="toc-text">Recovery with logs</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#redo-logging"><span class="toc-text">Redo logging</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec10-guest-lecture1"><span class="toc-text">Lec10 Guest Lecture1</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#redo-logging-1"><span class="toc-text">Redo logging</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undoredo-logging-undo-rdoe"><span class="toc-text">Undo&#x2F;Redo logging: Undo + Rdoe</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#external-actions"><span class="toc-text">External Actions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#media-failuredisk-failure"><span class="toc-text">Media Failure(disk failure)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec12-concurrency"><span class="toc-text">Lec12 Concurrency</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#what-makes-a-schedule-serializable"><span class="toc-text">What makes a schedule serializable?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#conflict-serializability"><span class="toc-text">Conflict serializability</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#precedence-graphs"><span class="toc-text">Precedence graphs</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#enforce-serializability-via-2-phase-locking"><span class="toc-text">Enforce serializability via 2-phase locking</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec13-concurrency2"><span class="toc-text">Lec13 Concurrency2</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#pl"><span class="toc-text">2PL</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#optimistic-concurrency-validation"><span class="toc-text">Optimistic concurrency &#x2F; validation</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec14-concurrency3-and-distributed-databases"><span class="toc-text">Lec14 Concurrency3 and Distributed databases</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#concurrency-control-recovery"><span class="toc-text">Concurrency Control &amp; Recovery</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#distributed-databases"><span class="toc-text">Distributed databases</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec15-distributed-databases2"><span class="toc-text">Lec15 Distributed databases2</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#two-phase-commit-2pc"><span class="toc-text">two-phase commit (2PC)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cap-theorem"><span class="toc-text">CAP Theorem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#parallel-execution"><span class="toc-text">Parallel execution</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec16-cloud-database-systems"><span class="toc-text">Lec16 Cloud Database systems</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec17-guest-lecture2"><span class="toc-text">Lec17 Guest Lecture2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec18-streaming-systems"><span class="toc-text">Lec18 Streaming Systems</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lec19-security-and-data-privacy"><span class="toc-text">Lec19 Security and data privacy</span></a></li></ol></li></ol></div><div class="column is-9"><header class="my-4"><a href="/blog/tags/CS245"><i class="tag post-item-tag">CS245</i></a><a href="/blog/tags/Notes"><i class="tag post-item-tag">Notes</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">CS245-Notes</h1><time class="has-text-grey" datetime="2022-03-23T02:59:28.000Z">2022-03-22</time><article class="mt-2 post-content"><h1 id="cs245-lecture-notes">CS245 Lecture Notes</h1>
<p>Jiani Wang (jianiw@stanford.edu)</p>
<p>[TOC]</p>
<h2 id="lec1-introdution">Lec1 Introdution</h2>
<ul>
<li><p>Why study data-intensive system</p>
<ul>
<li>Most important computer application must manage, update and query datasets</li>
<li>more important with AI</li>
</ul></li>
<li><p>What are Data-Intensive Systems</p>
<ul>
<li>Relational databases (MySQL, Oracle)</li>
<li>Many system facing similar concerns</li>
</ul></li>
<li><p>Typical Challenges:</p>
<ul>
<li>Reliability</li>
<li>Concurrency</li>
<li>Performance</li>
<li>Access interface</li>
<li>Security</li>
</ul></li>
<li><p>Key issue and themes</p>
<ul>
<li>logical dataset(how to store data): table, graph</li>
<li>data mgmt system</li>
<li>Physical storage (data structure), eg B Tree (order data by first name), a big array, variable length tuple, etc.</li>
<li>Clients / users: get data, run computation, update data</li>
<li>Administrator: manage the system functionality</li>
</ul></li>
<li><p>Examples</p>
<ul>
<li>Relational databases:
<ul>
<li>ODBC: a protocol and standard API to query</li>
</ul></li>
<li>Tensorflow:
<ul>
<li>Physical Storage: Row-based storage and col-based storage
<ul>
<li>NCHW: N=batch, C = column, H = height, W= wides</li>
</ul></li>
</ul></li>
<li>Apache Kafka: message queue
<ul>
<li>Logical Data Model: streaming of record(a lot of bytes, do not care about structure)</li>
<li>Partitions over many machines</li>
<li>compaction: for older data to store more efficiently</li>
</ul></li>
<li>Apache Spark RDDs: map reduce</li>
<li><img src="/images/image-20220129163854850.png" alt="image-20220129163854850" style="zoom:50%;"></li>
</ul></li>
<li><p>Message queue System:</p>
<ul>
<li>What shoule happen if two consumers read() at the same time?
<ul>
<li>They should get different message</li>
<li>When should get same message: different consumers works on same pictures</li>
<li>API design - get same message or different</li>
</ul></li>
<li>What should happed if a consumer reads a message but then immediately crashes
<ul>
<li>need <strong>transactions</strong></li>
<li>API design: start() and done(), a timeout (if does not call done() after timeout, restart)</li>
</ul></li>
<li>Can a producer put in 2 messages atomically?
<ul>
<li>eg, Venmo transfer to 3 friends.</li>
<li>design API to do that atomically</li>
</ul></li>
</ul></li>
<li><p>Two Big Ideas</p>
<ul>
<li>Declarative interfaces: what they want, not how to do it
<ul>
<li>Examples: SQL,</li>
</ul></li>
<li>Transactions
<ul>
<li>Examples: SQL databases (), Apache Spark/MapReduce, Stream processing systems</li>
</ul></li>
</ul></li>
<li><p>History:</p>
<ul>
<li>Navigational Databases: a graph of records, an API to navigate from the links</li>
<li>Relational DB model: table with unique key identifying each row
<ul>
<li>eg, System R, Ingres, Oracle</li>
</ul></li>
<li>Relation = table with unique key identifying each row</li>
<li>Relational database: <strong>data independence ++;</strong></li>
</ul></li>
</ul>
<h2 id="lec2-system-r">Lec2 System R</h2>
<h3 id="system-r">System R</h3>
<ul>
<li><p>System R Design</p>
<ul>
<li>Already have essenstial the same architecture as a modern RDBMS
<ul>
<li><img src="/images/image-20220129225137364.png" alt="image-20220129225137364" style="zoom:33%;"></li>
<li>Also have: <u>transcations, multiple isolation levels, indexes</u></li>
</ul></li>
<li>relational database</li>
<li>Navigational vs Relational Database
<ul>
<li>Navigational: some query are fast, some are slow
<ul>
<li>manually design data stracture</li>
</ul></li>
<li>Why: some query may need to process more links and nodes</li>
<li>Why relational model more flexible:
<ul>
<li>do not have a fixed way of representing the "links" to query the data</li>
<li>can have all kinds of datastructure, like index on a column, like links</li>
</ul></li>
</ul></li>
<li>Why was System R build in 3 phases?
<ul>
<li>big project, try things, do next generation</li>
<li>Phase 0: single user, left out concurrency and locking</li>
</ul></li>
</ul></li>
<li><p>Storage in R Phase 0:</p>
<ul>
<li>XRM like key-value store</li>
<li>table: 32-bit pointers points to different domain</li>
<li>have reverse mapping (domain =&gt; tuple ID)</li>
<li>Think the table as a big array of bytes: <img src="/images/image-20220106183211557.png" alt="image-20220106183211557" style="zoom:33%;">
<ul>
<li>0, 1 is the row number (this is a row based table)</li>
</ul></li>
<li>columns are stored in different files</li>
<li>Why not store as "name, jobs, column"?
<ul>
<li>save space for duplicated values</li>
<li>make each tuple is <strong>fixed length</strong>, can know the position by calculating the bias</li>
<li>easy to add new tuples, do not need to rewrite anything</li>
</ul></li>
<li>What was the issue with this design
<ul>
<li>Too many IOs
<ul>
<li>for every record, need to read from different files, seek time latency</li>
<li>Use inversion to find TIDs with a given value for a file =&gt; get a list of TID, then get all the values</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Storage System R Phase 1</p></li>
<li><p>B-tree nodes contain values of the columns indexed on; data pages can contain <strong>all fields</strong> of the record</p>
<ul>
<li><strong>Searching for a range</strong> is faster than XRM</li>
<li><strong>look at one record, and print all the fields</strong> is faster than Phase 0 (Read all fields from data page may only need single IO)</li>
</ul></li>
<li><p>API</p>
<ul>
<li>EXISTS, LIKE, OUTER JOIN</li>
<li><code>prepare()</code> with a placeholder in SQL</li>
</ul></li>
<li><p>Query Optimizer</p>
<ul>
<li>how did system R optimizer change after Phase 0?
<ul>
<li>changed metric</li>
<li>Phase 0: metric is <strong>number of tuples</strong> match a query, only look at IO cost</li>
<li>Phase 1: count all IO cost of all data structure, also take CPU time into considerations (total IO + CPU time)</li>
</ul></li>
</ul></li>
<li><p>Query Compliation</p>
<ul>
<li>Why did System R complie queries to assembly code?
<ul>
<li>assemble SQL, fast, easy</li>
<li>have an interpreter for SQL in Phase 0, slow</li>
</ul></li>
<li>Do database still do assemble today?
<ul>
<li>NO.</li>
<li>Because CPU is faster to do things like checking equal, the most time consuming thing is waiting for IO
<ul>
<li>Assemble: make the CPU calcuation faster</li>
</ul></li>
<li>maintain compiler is expensive</li>
<li>But do it sometime: need to optimize compute time for analysitic database</li>
</ul></li>
</ul></li>
<li><p>Recovery</p>
<ul>
<li>transaction failure: applications are allowed to abort transcation in the middle</li>
<li>Storage Media Failure / Disk Failure
<ul>
<li>have a backup disk, sync</li>
<li>backup disk need to have change log and older tables
<ul>
<li>change log on backup disk and primary disk</li>
<li>before write to main disk, write to change log on backup disk. Periodically write to backup disk</li>
<li>nice to have a change log also on the main disk if backup disk goes away</li>
<li>append to change log is sequential write, is faster (another reason to have change log). After you write the updates of a transcation to the log (on disk) , you can tell the user the transcation is finished</li>
</ul></li>
</ul></li>
<li>Crach Failures:
<ul>
<li>RAM contains data: Buffered pages, in-progress transactions</li>
<li>shadow pages: write to a seprate place on disk, update the pointer to latest page
<ul>
<li>deal with in-progress transactions: do not swap pointers, use the old pages and logs to recovery transactions need to cancel</li>
</ul></li>
<li>Why do we need both shadow pages and a change log?
<ul>
<li>only logs is OK (fewer IO). Today no shadow pages.</li>
</ul></li>
</ul></li>
<li>Transcation Failure:
<ul>
<li>could decide whether to cancel the transcation based on what you already read in the transaction, even after update</li>
</ul></li>
</ul></li>
<li><p>Locking:</p>
<ul>
<li>tradeoff:
<ul>
<li>finer-grained(for small unit data/sepcific operation)</li>
<li>Coarser-grained locking: whole table/ broader operaions</li>
<li>fine-grained: less chance of contention, but overhead(any syscall to lock is costly, spend CPU instructions to check who owns the lock) from thrashing</li>
</ul></li>
<li>Even if fine-grained locking were free, in some cases where it would give unacceptable performance
<ul>
<li>every one always write/read to same record</li>
<li>read the whole table to do some computation, need to lock the read to whole table, others can not write</li>
</ul></li>
</ul></li>
<li><p>Isolation level:</p>
<ul>
<li>Strong: can't see others changes</li>
<li>weak isolation level: high concurrency</li>
<li>predicate locks: use extra fine-grained locking</li>
<li>System R start with "predicate locks" based on expressions: fine-grained lock
<ul>
<li>then move to hierarchical locks: record/page/table, with read/write types and intentions</li>
</ul></li>
<li>3 levels:
<ul>
<li>Level1: Transcation may read uncommitted data</li>
<li>Level2: Transcation may only read committed data, but successive read may change</li>
<li>Level3: Successive reads return same value (people today chose this one)</li>
<li>Most apps chose Level 3 since others weren’t much faster</li>
</ul></li>
</ul></li>
<li><p>Alternatives to Locking</p>
<ul>
<li>Opitmistice concurrency control</li>
<li>MVCC: multi view concurrency control, something like git (you have a copy of the data that will not change, merge changes back to main)</li>
</ul></li>
<li><p>Authorization:</p>
<ul>
<li><strong>view-based</strong> access control: define SQL view and give user access</li>
<li>Elegant implementation: add the user’s SQL query on top of the view’s SQL query</li>
</ul></li>
<li><p>User Evaluation</p></li>
</ul>
<h3 id="relational-dbms-architecture">Relational DBMS architecture</h3>
<ul>
<li>Typical RDBMS Architecture
<ul>
<li><img src="/images/image-20220130003635063.png" alt="image-20220130003635063" style="zoom:33%;"></li>
<li>Concurrency control: control all the locks</li>
<li>Buffer: the pages that was loaded into memory</li>
<li>Some of the components have clear boundaries and interfaces for modularity
<ul>
<li>Other components can interact closely</li>
</ul></li>
</ul></li>
<li>2 big class of RDBMS:
<ul>
<li>Transcation DBMS: for real-time apps
<ul>
<li>eg, MySQL, Postgres, Oracle</li>
</ul></li>
<li>Analytical DBMS: data warehouses, heavy read; large, parallel but mostly read-only analytics
<ul>
<li>eg, store the history / log of bank transactions</li>
<li>MapReduces, datalakes</li>
</ul></li>
</ul></li>
<li><img src="/images/image-20220106193816585.png" alt="image-20220106193816585" style="zoom:50%;">
<ul>
<li>log queries: if you are querying all table and do some analys, if the database down, you want to recover the query form the middle</li>
</ul></li>
</ul>
<h2 id="lec3-database-system-architecture-2-storage">Lec3 Database System Architecture 2 &amp; Storage</h2>
<h3 id="alternative-dbms-structures">Alternative DBMS structures</h3>
<ul>
<li>decouple DBMS into query processing and storage managment
<ul>
<li>Large-scale file system or blob stores</li>
<li>Open storage and metadata formats
<ul>
<li>Parque and json are file format</li>
<li>HIVE build on hadoop and have RDBMS to manage the file belongs to which table</li>
<li>Hive, delta lake has computation engines</li>
</ul></li>
<li>Processing engines:
<ul>
<li>Spark, presto, etc. Do computation</li>
</ul></li>
<li><img src="/images/image-20220214211709992.png" alt="image-20220214211709992" style="zoom:50%;"></li>
</ul></li>
<li>Decouple Query Processing from Storage Managemenet:
<ul>
<li>Pros: store data in cheap format and large storage, do different kinds of work on that</li>
<li>Can scale compute independently for storage</li>
<li>Cons: harder to guarantee isolation.</li>
</ul></li>
<li>Change the <u>Data Model</u>: non-relational database
<ul>
<li>key-value stores</li>
<li>Message queue: FIFO</li>
</ul></li>
<li>Change the <u>compute Model</u>:
<ul>
<li>Streaming: query run forever, not lock the records; does not fits with consistency</li>
<li>Eventual consistency: relaxing consistance, hanld it at app level</li>
</ul></li>
<li>Different hardware Settings
<ul>
<li>Distributed databases: need seperate locking, storage manager</li>
<li>public cloud: serverless</li>
</ul></li>
<li>Relation database: form data as tables</li>
<li>One trend is to break apart this monolithic architecture into specialized components</li>
</ul>
<h3 id="storage-storage-hardware">Storage: Storage Hardware</h3>
<ul>
<li><p>Storage Performance Metrics:</p>
<ul>
<li>Latency (s)</li>
<li>throughput (bytes/s)</li>
</ul></li>
<li><p>end to end time</p></li>
<li><p>Disk:</p>
<ul>
<li><strong>Time = Seek time + Rotational Delay + Transfer Time + Other</strong></li>
<li>Seek time: disk &gt;&gt; SSD</li>
<li>Rotation Delay: on average half a circle, 1/2 revolution</li>
<li>Transfer time: size / T for contiguous read</li>
</ul></li>
<li><p>What happen if <strong>read</strong> next block on disk</p>
<ul>
<li><p>Double buffer: tell the filesystem/disk to read, issue a request to say copy the next page to another buffer. prefetch ??? Might miss the next one</p></li>
<li><p>time to get next one: sequentail access generally much faster than random access</p></li>
<li><p>Time to get = block size / T + negligible</p>
<ul>
<li><p>Potential slowdowns:</p>
<p>Skip gap</p>
<p>  Next track</p>
<p>  Discontinuous block placement</p></li>
</ul></li>
<li><p>Cost of <strong>writing</strong>: Similar to Reading</p>
<ul>
<li>If want to Verify: wait a whole cycle to check whether the write is right</li>
</ul></li>
<li><p>Cost of <strong>Modify</strong> Block:</p>
<ul>
<li>read block, modify in memory, write back</li>
<li>might be a little bit slower</li>
</ul></li>
</ul></li>
<li><p>DRAM: read from DRAM is a cache line (64 bytes)</p>
<ul>
<li>CPU prefecting</li>
<li><strong>Min read from DRAM is a cache line</strong></li>
<li>random read is still slower than sequentail read
<ul>
<li>Place co-accessed data together!</li>
</ul></li>
<li>Accessing 8 byte records in a DRAM with 64-bytes cache line:
<ul>
<li>How much slower is random vs sequential? 8 times slower
<ul>
<li>how well utilize the bandwidth</li>
<li>because of the latency: every time fetch 64KB cache line, only 8KB of them is useful, other data are wasting bandwidth</li>
<li>the most time comsuming thing is copy from DRAM to the cache line</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Five minute Rule: trade-off between use disk or use DRAM</p>
<ul>
<li>A page is accessed every X seconds</li>
<li>Disk costs D dollars and can do <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0" xmlns="http://www.w3.org/2000/svg" width="1.14ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 504 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g></g></g></svg></mjx-container></span> optetaions/sec, cost of keeping this page on disk is :
<ul>
<li><img src="/images/image-20220130140717288.png" alt="image-20220130140717288" style="zoom:30%;"></li>
</ul></li>
<li>1MB of RAM costs M dollars and holds P pages, then cost of keeping it in DRAM is: <img src="/images/image-20220130140750681.png" alt="image-20220130140750681" style="zoom:30%;"></li>
<li>The page is worth caching when <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex" xmlns="http://www.w3.org/2000/svg" width="13.15ex" height="1.952ex" role="img" focusable="false" viewBox="0 -705 5812.4 862.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="TeXAtom" transform="translate(748,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(878,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1344,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2647,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="msub" transform="translate(3702.7,0)"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="TeXAtom" transform="translate(748,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(520,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(865,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(1334,0)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g></g></g></g></svg></mjx-container></span></li>
<li>Compare between SSD and hard disk
<ul>
<li>C_mem &lt; C_disk, if X &lt; 5mins (now 4h). For data that access frequently, store in DRAM/memory</li>
<li>disk latency has been approved</li>
</ul></li>
</ul></li>
<li><p>Combining Storage Devices/RAID:</p>
<ul>
<li>increases <strong>performance</strong> and <strong>reliability</strong></li>
<li>Different RAID levels: (Stratigy of using multiple disks)
<ul>
<li><img src="/images/image-20220130141630358.png" title="fig:" alt="image-20220130141630358"></li>
<li>RAID 0 / Striping: for performance. Read from two disks, write to 2 disks</li>
<li>RAID 1 / Mirroring: for reliability (twice perforamce for read)
<ul>
<li>read a file A from two disks, and write to both disks</li>
</ul></li>
<li>RAID 1 / Mirroring Across: helps with reads (get A1A2 from Disk1 and get A3 A4 from Disk2), does not helps with writing</li>
<li>RAID 5 / Stripping+ 1 parity disk: Ap = A1 ^ A2 ^ A3 (bit wise XOR of all the part)
<ul>
<li>Can afford loss one disk, recover using Ap</li>
<li>1 parity for fault discovery</li>
<li>Paralell when read, 4 disks = use 4 disk for read bandwidth</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Handling Storage Failures</p>
<ul>
<li>Detection: checksum;</li>
<li>Correction: need replicating data</li>
</ul></li>
<li><p>In all cases, data layout and access pattern matter because random ≪ sequential access</p></li>
</ul>
<h2 id="lec4-data-storage-formats">Lec4 Data Storage Formats</h2>
<ul>
<li>Data items -&gt; records -&gt; blocks -&gt; files</li>
</ul>
<h3 id="record-encoding">Record encoding</h3>
<ul>
<li><p>Three concerns of designing Storage Formats:</p>
<ul>
<li>Access time</li>
<li>Space</li>
<li>easy to update</li>
</ul></li>
<li><p>general Setup:</p>
<ul>
<li>record collection + index (index on primary key, the data is ordered by primarity key) + second index</li>
</ul></li>
<li><p>What are the data items we want to store</p>
<ul>
<li>bytes (8 bits): map different data types to bytes</li>
<li>Fixed length: integer: fixed # of bits; Floating points: n-bit mantissa, m-bit exponent; character</li>
<li>Variable length: string, bag of bits</li>
<li>representing Nothing: NULL(Not same as 0 or "")
<ul>
<li>sepcical sentinel value in fix-length</li>
<li>Boolean is NULL flag</li>
<li>Just skip the field in a sparse record format</li>
</ul></li>
<li>Which data type have value to represent NULL?
<ul>
<li>String/Character?</li>
<li>Floating Point? NOT A NUMBER (a special combination of bits, pick up one)</li>
</ul></li>
</ul></li>
<li><p>Record Encoding</p>
<ul>
<li><p>independent choice of f</p>
<ul>
<li>Fixed vs variable <strong>format</strong></li>
<li>Fixed vs variable <strong>length</strong></li>
</ul></li>
<li><p>Fixed Format</p>
<ul>
<li><p>a schema for all records in table specifies:</p>
<p>- # of fields</p>
<p>- type of each field</p>
<p>- order in record</p>
<p>- meaning of each field</p></li>
</ul></li>
<li><p>Variable Format: eg, Json data, protocal buffer</p>
<ul>
<li><img src="/images/image-20220130150002957.png" alt="image-20220130150002957" style="zoom:50%;"></li>
<li>Variable format useful for <u>sparse records, repeating fields, evolving formats</u></li>
<li>But may waste space (a lot of staff before acture data)</li>
</ul></li>
<li><p>Variants Between Fixed and Variable Format</p>
<ul>
<li>eg, Include a <strong>record type</strong> in record</li>
</ul></li>
</ul></li>
</ul>
<h3 id="collection-storage">Collection Storage</h3>
<p>Record =&gt; blocks =&gt; files</p>
<ul>
<li><p>Efficiency question:</p>
<ul>
<li><strong>locality</strong>: read near items</li>
<li><strong>searchability</strong>: quickly find relevant records; how many IO it takes to find a item</li>
</ul></li>
<li><p>Locality:</p>
<ul>
<li>Read different field of same records</li>
<li>Read same field: Read field1 of record1 and read field1 of record2
<ul>
<li>column store is 3x less IO: because for row store, almost read the whole table and get age field.</li>
</ul></li>
<li>row store &amp; column store
<ul>
<li>Accessing all fields of one record: 1 random I/O for row, 3 for column</li>
<li>Accessing one field of all records: 3x less I/O for column store
<ul>
<li>If data is on disk: For row store, read the whole table</li>
<li>If data is on memory: For row store, bring a whole cache line to CPU L1cache, basically reading the whole table</li>
</ul></li>
</ul></li>
<li>Hybrids store between Row and Column
<ul>
<li>column groups: might be accessed together/co-accessed</li>
<li>row columns: group a couple of rows together and store them by column
<ul>
<li><img src="/images/image-20220130152810879.png" alt="image-20220130152810879" style="zoom:50%;"></li>
</ul></li>
<li>depends on storing on memory or disk??? Consider the block size of disk, and cache line size.
<ul>
<li>for disk, you need to wait for the disk to spin and skip the data in between. (wait time depends on how many data in between)</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Searchability: <strong>Ordering, Paritions</strong></p>
<ul>
<li><p>Ordering the data:</p>
<ul>
<li>closer I/O if queries tend to read data with nearby values of the field</li>
<li>Add Index to increase serchability</li>
<li>cons: need to maintain ordering when insertion/add data, slow when modify/insertion</li>
</ul></li>
<li><p>Partitions:</p>
<ul>
<li>Place data into buckets based on a field, but not necessarily fine-grained order (could just append at the end of buckets)</li>
</ul></li>
<li><p>Have searchability on <strong>Multiple fields</strong> at once:</p>
<ul>
<li><p>Method1: Multiple partition or sort keys, composite keys</p>
<ul>
<li>eg, partition using (date, user_id).</li>
<li>downside: if the first level of partition/sorting result in small buckets, hard to search on second level, because have a lot of buckets need to search</li>
</ul></li>
<li><p>Method2: Interleaved orderings such as Z-ordering, eg (date, user_id)</p>
<ul>
<li><img src="/images/image-20220113190347826.png" alt="image-20220113190347826" style="zoom:50%;"></li>
<li>split into 4 and create a z</li>
</ul>
<p><img src="/images/image-20220130154334439.png" alt="image-20220130154334439" style="zoom:50%;"></p>
<ul>
<li>the data points of (date, uid) is on the corner of "Z"</li>
<li>store the data points follow the zigzag line</li>
<li>good partial locality on both dimensions: eg, the green lines shows the locality of 'date' dimotion <img src="/images/image-20220113190418814.png" alt="image-20220113190418814"></li>
<li>Z ordering - bit interleaving:
<ul>
<li><img src="/images/image-20220113190958210.png" alt="image-20220113190958210" style="zoom:50%;"></li>
<li>take the generated 8 bits and sort by this 8 bits value, basically like Z-ordering</li>
</ul></li>
</ul></li>
<li><p>Other methods, Multiple demsional clustering</p></li>
</ul></li>
</ul></li>
<li><p>How to store <strong>records</strong> in <strong>blocks</strong> and files?</p>
<ul>
<li>records are in different size,</li>
<li>separating records: tell where is the begin and where is the end
<ul>
<li>Fixed size: easy to skip to the start of a record, might waist spaces</li>
<li>special marks:</li>
<li>give record length (within each record, or in block header )</li>
</ul></li>
<li>Spanned vs unspanned
<ul>
<li><img src="/images/image-20220130162710084.png" alt="image-20220130162710084" style="zoom:33%;"></li>
<li>unspanned:
<ul>
<li>cons: may waste space</li>
<li>pros: easy to find the start of every record</li>
<li>when insert new records, need to manage all the small blank spaces</li>
<li>when deleteing records, have a lot small empty spaces, which can not fit large records.</li>
</ul></li>
<li>spanned: allow the block to go across different blocks
<ul>
<li>cons: fragmenentation for spanned; need more IO to read a record (if the record on two different block)</li>
<li>pros: not wasting space</li>
<li>If the record is really large, larger than a block, MySQL will keep the long record in other places</li>
</ul></li>
</ul></li>
<li>Indirection: how to refer to other records:
<ul>
<li>Fully Physical references: record Address ID = (device ID, cylinder ID, )</li>
<li>Fully Indirect references:
<ul>
<li>Record ID is assigned, a unique ID without any special meaning</li>
<li><img src="/images/image-20220130163452048.png" alt="image-20220130163452048" style="zoom:50%;"></li>
</ul></li>
<li>Tradeoff:
<ul>
<li>Flexibility &lt;=&gt; cost</li>
<li>Indirect: 2 IO for look up a record; but more flexible (move data records only need to change the physical addr in the map)</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Inserting Records:</p>
<ul>
<li>Easy case: records not ordered, just put and the end of file or in a free space
<ul>
<li>If records are variable-length, harder</li>
<li>like malloc() and free() in OS class, how to manage free space to be efficient (find a space given size)</li>
</ul></li>
<li>Harder case: records are ordered
<ul>
<li>If free space close by, not too bad</li>
<li>Otherwise, use an <strong>overflow</strong> area and reorganize the file periodically</li>
</ul></li>
</ul></li>
<li><p>Deleting Records:</p>
<ul>
<li>Immediately reclaim space</li>
<li>OR, Mark deleted And keep track of freed spaces for later use</li>
</ul></li>
<li><p>Compressing Collections:</p>
<ul>
<li>Usually for a block at a time</li>
<li>Column store is more easy to compress, more compressible
<ul>
<li>Item in the column is very similar, have similar items together</li>
</ul></li>
<li>Can be integrated with execution (C-Store)</li>
</ul></li>
</ul>
<h2 id="lec5-storage-foramt-c-store-paper">Lec5 Storage Foramt C-Store paper</h2>
<h3 id="c-store-paper">C-Store Paper</h3>
<ul>
<li><p>Co-designing comput and storage</p></li>
<li><p>C-store stire data in <strong>Projections</strong>:</p>
<ul>
<li>subset of columns, might sort in different order</li>
<li>Join indexes to find join multiple columns</li>
</ul></li>
<li><p>C-Store Compression</p>
<ul>
<li>NULL Compression: compress leading 0 in Integers, nothing to do with SQL NULL</li>
<li>Dictionary encoding:
<ul>
<li>Keys could be a combination of columns</li>
<li>this was done in bulk
<ul>
<li>eg, 4 column, each might have value 0, 1, 2, 3. Store 4 columns together as key: 0000, 0133</li>
</ul></li>
<li>commen things should be encoded with fewer bytes</li>
</ul></li>
<li>Bit-vector encoding
<ul>
<li>eg, 0=001, 1 = 100, 2= 010</li>
<li>useful when lookup a specific value</li>
</ul></li>
<li>Lempel-Ziv</li>
</ul></li>
<li><p>Experiments:</p>
<ul>
<li><p>100 million 4-byte integers</p></li>
<li><p>Sorted runs: # of sorted values that apear one after the other, consecutive number that are ordered</p>
<ul>
<li>0 0 1 2 0 1 1 3 9 0 1 2 1 2: 4 sorted runs, 0 0 1 2, 0 1 1 3 9,</li>
<li>projections are sorted by several columns/multiple keys, so it have several "sorted run" rather than a giant sorted run.
<ul>
<li>Sorted run pattern appears a lot</li>
</ul></li>
</ul></li>
<li><p>Column size: <img src="/images/image-20220131104203763.png" alt="image-20220131104203763" style="zoom:50%;"></p></li>
<li><p>RLE Compression in sorted runs of length 50</p>
<ul>
<li>for every value in the run, store a integer of how many times it appears</li>
<li>If 25 distinct value, average every number appear 2 time</li>
</ul></li>
<li><p>Bit compression corss No-compression at 32 distinct values: integer is 32 bit</p></li>
<li><p>Time:</p>
<p><img src="/images/image-20220131104643105.png" alt="image-20220131104643105" style="zoom:50%;"></p>
<ul>
<li>No compression: time increases for query like "COUNT(*) GROUP BY", why?
<ul>
<li>keep a <strong>hash count</strong>, for each value =&gt;count. Use for loop to check every record in the column store, then count++;</li>
<li><strong>Branch</strong>, If you have multiple possible values, the CPU might have a lot of branches, and it will guess one and suppose the value matchs
<ul>
<li>For small distinct values and long sorted runs, same value appears a lot of times</li>
</ul></li>
<li>Could also because of memory system: already load a value into register, if next value is same, directly++?</li>
</ul></li>
</ul></li>
<li><p>How would the result change on SSD?</p>
<ul>
<li>IO will be come very fast, If some compression method is IO-bound, it will become faster</li>
<li>Dictionary Compression might become worse, because it needs to lookup dictionary in memory and count; other thing like bit-vector and RLE might become faster, because do not need to lookup and know the value ???</li>
<li>if the read speed of disk reaches maximum of the disk (bits/s), it IO-bound process</li>
</ul></li>
</ul></li>
</ul>
<h3 id="index">Index</h3>
<ul>
<li><p>Find a <u>specific key</u> or <u>range query</u> or <u>nearest data point</u></p></li>
<li><p>trade-offs: index size, query performance, cost to update indexes</p></li>
<li><p>adapt data structure to work well on disk (care about IOs)</p></li>
<li><p>Conventional indexes / Tree-based</p>
<ul>
<li><p>dense index</p>
<ul>
<li>have index on every single key, and point to each record</li>
<li>When a record in file is really long, use index to search</li>
<li>index pages have 4 items, Data pages</li>
<li>Index pages can contain more information, and can <u>be cached in memory</u></li>
</ul></li>
<li><p>Sparse index</p>
<ul>
<li>skip some keys, pointing to the <u>begining of each data page</u></li>
<li>the table need to be sorted sequential</li>
<li>2-level sparse index, like a search tree</li>
<li>File and 2nd level index blocks <u>need NOT be contiuous on disk</u>, might be in linked list
<ul>
<li>easy to modify and insert</li>
<li>1st level index need to be continuous or linked list</li>
<li><img src="/images/image-20220214234235179.png" alt="image-20220214234235179" style="zoom:50%;"></li>
</ul></li>
</ul></li>
<li><p>Sparse vs Dense</p>
<ul>
<li><p>Sparse: Less space usage, can keep more of index in memory</p></li>
<li><p>Dense: Can tell whether a key is present without accessing file</p></li>
<li><p>(Later: sparse better for insertions, dense needed for secondary indexes)</p></li>
</ul></li>
<li><p>Terms:</p>
<ul>
<li>Search key of an index: can be multiple fileds</li>
<li>Primary index: inde on primary key (the file is sorted by the key)</li>
<li>Secondary index: index on anything else that the file is not sorted by</li>
<li>dense index: contain all the values</li>
</ul></li>
<li><p>Handling duplicate keys:</p>
<ul>
<li>For a primary index, can point to 1st instance of each item (assuming blocks are linked)</li>
<li>For a secondary index, need to point to a list of records since they can be anywhere</li>
</ul></li>
<li><p>Hard to insert and delete</p>
<ul>
<li>deletion: Sparse Index
<ul>
<li>need to shift the data, make the blank space at the end of block</li>
<li>can leave a blank space in index page or file page</li>
<li>Dense index need more work: always need to update pointer.</li>
</ul></li>
<li>Insertion: sparse index
<ul>
<li>Need to move things around<img src="/images/image-20220208142950354.png" alt="image-20220208142950354" style="zoom:50%;"></li>
<li>Another strategy: use overflow blocks <img src="/images/image-20220214235706627.png" alt="image-20220214235706627" style="zoom:50%;"></li>
</ul></li>
</ul></li>
<li><p>Secondary indexes:</p>
<ul>
<li>sparse index does not work</li>
<li>spase higher level (1st) + dense index (2rd)</li>
</ul></li>
<li><p>search key of an index: can be multiple fields</p></li>
<li><p>Handling Duplicate keys</p>
<ul>
<li>for the secondary index, need to point to a list</li>
<li><img src="/images/image-20220208143234350.png" alt="image-20220208143234350" style="zoom:33%;"></li>
<li>bucket advantages: Can compute complex queries through Boolean operations on record pointer lists <img src="/images/image-20220215000206866.png" alt="image-20220215000206866" style="zoom:50%;">
<ul>
<li>First get the buckets according to the dept. index and Floor index, intersect them.</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>B-trees</p>
<ul>
<li><p>top level = 1 page</p></li>
<li><p>degree of the tree n=3: max number of value in each node</p></li>
<li><p>B Tree rules:</p>
<ul>
<li><img src="/images/image-20220208145514420.png" alt="image-20220208145514420">half full to toally full</li>
</ul></li>
<li><p>Insert key</p>
<ul>
<li>make leaf node half full to toally full</li>
<li>when insert, split a leaf node and create another one</li>
<li>leaf overflow, non-leaf overflow, add new root (the root)</li>
<li>add from lower level, recursively insert upper layer.</li>
</ul></li>
<li><p>Deletion from B+ tree</p>
<ul>
<li><ol type="a">
<li><p>Simple case: no example</p></li>
<li><p>Coalesce with neighbor (sibling)</p></li>
<li><p>Re-distribute keys</p></li>
<li><p>Cases (b) or (c) at non-leaf</p></li>
</ol></li>
</ul></li>
<li><p>What is optimal n?</p>
<ul>
<li>a index page could be 1 or more storage blocks</li>
</ul></li>
</ul></li>
<li><p>Hash indexes</p></li>
<li><p>Multi-key indexing</p></li>
</ul>
<h2 id="lec6-query-execution">Lec6 Query Execution</h2>
<h3 id="hash-table">Hash table</h3>
<ul>
<li><p>keep 50% - 80% full</p></li>
<li><p>Extendible hashing</p>
<ul>
<li>first use i bits of the h(K) to map it to buckets</li>
<li>points to a directory then points to buckets</li>
<li>Don't need to shuffle everything</li>
</ul></li>
<li><p>i=2, means the first 2 bit are used as key</p>
<ul>
<li>increasely add more detail</li>
<li><img src="/images/image-20220120152719204.png" alt="image-20220120152719204" style="zoom:33%;"></li>
<li>the first two pointers points to same places, because now there are not so much items begin with 0</li>
<li>if we insert 0111 and 0000, change i=1 to i=2 (change the local depth)</li>
<li>do not need to move a lot of data around, disk friendly hash table</li>
<li>For IO, need 2 IO to find the data (Not much better than tree)</li>
</ul></li>
<li><p>Will need chaining if values of h(K) repeat and fill a bucket</p></li>
</ul>
<h3 id="multiple-key">Multiple key</h3>
<ul>
<li><p>Strategies: 3 kinds</p></li>
<li><p>k-dimensional trees / k-d trees</p>
<ul>
<li>split on one dimensional, make the division as even as possible</li>
<li>use second dimension to split big buckets</li>
<li>Efficient range query in both dimensions</li>
</ul></li>
<li><p>How to only search for y, eg, search for x=15 and y &gt; 30?</p>
<ul>
<li><img src="/images/image-20220208164124018.png" title="fig:" alt="image-20220208164124018"></li>
</ul></li>
<li><p>How to only search for y?</p></li>
<li><p>Always used in graphical data</p></li>
<li><p>Some database examples: Mysql, Apache</p></li>
<li><p>Storage system examples:</p>
<ul>
<li>MySQL:<img src="/images/image-20220215005954550.png" alt="image-20220215005954550" style="zoom:50%;"></li>
<li>Apache Parquet + Hive:<img src="/images/image-20220215010005910.png" alt="image-20220215010005910" style="zoom:50%;"></li>
</ul></li>
</ul>
<h3 id="query-execution">Query Execution</h3>
<ul>
<li><p>logical query plan: relational algebra</p>
<ul>
<li>Physical query plan: real data structures and algorithm</li>
</ul></li>
<li><p>Plan optimization Methods:</p>
<ul>
<li>Rule-based:</li>
<li>Cost-based:</li>
<li>Adaptive: update execution plan at runtime</li>
</ul></li>
<li><p>Execution Methods:</p>
<ul>
<li>Interpretation:walk through query plan operators for each record</li>
<li>Vecotrization: walk through in batches</li>
<li>Compilation: generate code</li>
</ul></li>
<li><p>Reltional operators</p>
<ul>
<li>bag of tuples: unordered but each tuple may repeat</li>
<li>set of tuples: unordered and each tuple can NOT repeat</li>
<li>set union: make distinct, more expensive
<ul>
<li>bag union (UNION ALL): keep everything duplicated</li>
</ul></li>
<li>Operators:
<ul>
<li><img src="/images/image-20220215010552529.png" alt="image-20220215010552529" style="zoom:50%;"></li>
<li><img src="/images/image-20220215010614930.png" alt="image-20220215010614930" style="zoom:50%;"></li>
<li><img src="/images/image-20220215010659287.png" alt="image-20220215010659287" style="zoom:50%;"></li>
</ul></li>
<li>View Operation: operate on table
<ul>
<li>selection: select rows</li>
<li>projection: compute a new thing, expression(r)</li>
<li>Aggregation</li>
</ul></li>
<li>Properties:
<ul>
<li>selects: use "SUM" option for bag unions</li>
<li>projection: <img src="/images/image-20220120161059107.png" alt="image-20220120161059107" style="zoom:20%;"></li>
<li>only read those columns will be used</li>
</ul></li>
</ul></li>
<li><p>Example SQL query:</p>
<ul>
<li><code>IN</code> is a cross product + selection!</li>
</ul></li>
<li><p>One physical plan:</p>
<ul>
<li>build index on one table and sequencially scan another table
<ul>
<li>Which table to hash?
<ul>
<li><strong>hash the small table</strong>, small table can live in CPU cache</li>
<li>hash table should not in disk</li>
</ul></li>
</ul></li>
<li>building hash is linear time, sequential scan also have linear time</li>
</ul></li>
<li><p>Execution methods</p>
<ul>
<li><p><strong>Interpretation</strong>:</p></li>
<li><p><img src="/images/image-20220208205208695.png" alt="image-20220208205208695" style="zoom:33%;"></p></li>
<li><p>For Select, it will continue call parent.next(), and check whether the condition satisfies</p>
<ul>
<li>pros and cons
<ul>
<li>pros: it's simple</li>
</ul></li>
<li>cons: speed.next() need to call compute(), compute() can be any computation, so compiler will made it to a branch, slow down CPU</li>
</ul></li>
<li><p><strong>vectorization</strong>: an Operators and Expressions works on a batch of values.</p>
<ul>
<li>tuplebatch: work on rows; valuebatch: a batch of columns</li>
<li>Pros: works great for analysictial database</li>
<li>Cons: data goes between CPU and L1 Cache often.</li>
<li>Typical implementation:
<ul>
<li>values store in columnar arrays, with a seperate bit array to mark nulls</li>
<li>tuple batches fit in L1 or L2 cache</li>
<li>Operators use SIMD instructions to update both values and null fields <u>without branching.</u></li>
</ul></li>
</ul></li>
<li><p>Compilation</p>
<ul>
<li>pros and cons:<img src="/images/image-20220215013831996.png" alt="image-20220215013831996" style="zoom:33%;"></li>
</ul></li>
</ul></li>
<li><p>What's used today?</p>
<ul>
<li>Transactional databse: record-at-a-time interpretation</li>
<li>Analytical systems: vectorization, sometimes compilation</li>
<li>ML libs: mostly vectorization, some compilation</li>
</ul></li>
<li><p>From CS145:</p>
<ul>
<li>push projection <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0" xmlns="http://www.w3.org/2000/svg" width="1.697ex" height="1.538ex" role="img" focusable="false" viewBox="0 -680 750 680"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="3A0" d="M128 619Q121 626 117 628T101 631T58 634H25V680H724V634H691Q651 633 640 631T622 619V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V634H232V348L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V619Z"></path></g></g></g></svg></mjx-container></span> through (1) selection (2) join</li>
<li>Push selection <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex" xmlns="http://www.w3.org/2000/svg" width="1.292ex" height="1ex" role="img" focusable="false" viewBox="0 -431 571 442"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g></g></g></svg></mjx-container></span> through (3) selection (4) Projection (5) join</li>
</ul></li>
</ul>
<h2 id="lec7-query-optimization">Lec7 Query Optimization</h2>
<ul>
<li>What can we optimize
<ul>
<li>Operator graph</li>
<li>Operator implementations</li>
<li>Access path</li>
</ul></li>
</ul>
<h3 id="rule-based-optimization">Rule-based optimization</h3>
<ul>
<li><p>What is a Rule?</p>
<ul>
<li>Each rule is typically a function that walks through query plan to search for its pattern</li>
<li>eg, OR TRUE, if <code>node.left == Literal(true)</code> , redundant rule
<ul>
<li>Literal is a constant</li>
</ul></li>
<li>Rules are ofen grouped into <strong>phases</strong>
<ul>
<li>use <code>loc IN (CA, NY)</code> instead of <code>loc == CA || loc == NY</code> can reduce the branches, maybe it's a hash table lookup</li>
<li><img src="/images/image-20220208230634619.png" title="fig:" alt="image-20220208230634619"></li>
<li>do age&gt;=18 first, we left less data (reduce more data firstly)</li>
</ul></li>
</ul></li>
<li><p>Spark: easy to extend optimizer</p></li>
<li><p>If we have a lot of optimizer rules, how to check if the rule applies for a query?</p>
<ul>
<li>indexing the query plan to find all the plan that contains <code>or</code> , eg, can find all the nodes with "OR" fast</li>
</ul></li>
<li><p>Common Rule-Based optimization</p>
<ul>
<li><p>Index column predicate ⇒ use index</p>
<p>Small table ⇒ use hash join against it</p>
<p>Aggregation on field with few values ⇒ use in-memory hash table</p></li>
<li><p>selecting access paths and operator i</p></li>
<li><p>Pushing projects as far down as possible - greedy algorithm</p></li>
<li><p>Pushing selection as far down as possible - greedy algorithm</p></li>
<li><p>Example, if there is a index on A/B, can use index to do selection, so first one is better (do selection first???)</p></li>
</ul></li>
<li><p>Some times project Rules can backfire</p>
<ul>
<li>eg, <img src="/images/image-20220208232437154.png" alt="image-20220208232437154" style="zoom: 25%;"></li>
<li>If we have index on both A and B, use index. <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0" xmlns="http://www.w3.org/2000/svg" width="1.697ex" height="1.538ex" role="img" focusable="false" viewBox="0 -680 750 680"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="3A0" d="M128 619Q121 626 117 628T101 631T58 634H25V680H724V634H691Q651 633 640 631T622 619V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V634H232V348L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V619Z"></path></g></g></g></svg></mjx-container></span> is an operator to scan all the table (So we should not push projection into the most inner layer)</li>
</ul></li>
</ul>
<h3 id="data-statistics">Data Statistics</h3>
<ul>
<li><p>Data Statistics</p>
<ul>
<li><p>T(R) = # of tuples in R</p>
<p>S(R) = average size of R’s tuples 3in bytes</p>
<p>B(R) = # of blocks to hold all of R’s tuples</p>
<p>V(R, A) = # distinct values of attribute A in R</p></li>
<li><p>Intermediate tables: estimate</p>
<ul>
<li><code>(R join S) join T</code> is better than <code>R join (S join T)</code> if (R join S) give us less tuple</li>
<li>have smaller intermediate table</li>
</ul></li>
</ul></li>
<li><p>Size Estimates:</p>
<ul>
<li><p>W = R1 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0.02ex" xmlns="http://www.w3.org/2000/svg" width="1.76ex" height="1.09ex" role="img" focusable="false" viewBox="0 -491 778 482"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g></g></g></svg></mjx-container></span> R2: s = s1 + s2, T = T1 * T2</p></li>
<li><p>W = <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.477ex" xmlns="http://www.w3.org/2000/svg" width="4.77ex" height="1.452ex" role="img" focusable="false" viewBox="0 -431 2108.5 641.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g><g data-mml-node="TeXAtom" transform="translate(604,-152.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mo" transform="translate(750,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1528,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g></g></g></g></g></svg></mjx-container></span>(R): T(W) = T(R)/V(R,A)</p></li>
<li><p>Domain = max - min</p></li>
<li><p>W = <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="4.77ex" height="1.541ex" role="img" focusable="false" viewBox="0 -431 2108.5 681.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g><g data-mml-node="TeXAtom" transform="translate(604,-152.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mo" transform="translate(750,0)"><path data-c="2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mi" transform="translate(1528,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g></g></g></g></g></svg></mjx-container></span>(R), guess T(R)/2 or T(R)/3</p></li>
<li><p>What about more complex expression?</p>
<ul>
<li>guess T(R)/2 or T(R)/3, sometimes works well</li>
</ul></li>
<li><p><strong>Join</strong>: W = R_1<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.011ex" xmlns="http://www.w3.org/2000/svg" width="2.036ex" height="1.154ex" role="img" focusable="false" viewBox="0 -505 900 510"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="22C8" d="M833 50T833 250T832 450T659 351T487 250T658 150T832 50Q833 50 833 250ZM873 10Q866 -5 854 -5Q851 -5 845 -3L449 226L260 115Q51 -5 43 -5Q39 -5 35 -1T28 7L26 11V489Q33 505 43 505Q51 505 260 385L449 274L845 503Q851 505 853 505Q866 505 873 490V10ZM412 250L67 450Q66 450 66 250T67 50Q69 51 240 150T412 250Z"></path></g></g></g></svg></mjx-container></span> R_2</p>
<ul>
<li>Estimate T(W):
<ul>
<li>if(VR1, A) &lt;= V(R2, A), for every tuple in R1, matches 1 or more in R2. Uniformaly distribution, 1 tuple matches T(r2)/V(R2,A)</li>
<li>T(W) = T(R1)*T(R2) / max(V(R1,A), V(R2,A)),<img src="/images/image-20220215015604251.png" alt="image-20220215015604251" style="zoom:33%;"> symmetric</li>
<li>Alternative, use DOM():<img src="/images/image-20220215015753837.png" alt="image-20220215015753837" style="zoom:50%;"></li>
</ul></li>
<li>Estimate V(W, A): <img src="/images/image-20220215020025486.png" alt="image-20220215020025486" style="zoom:50%;"></li>
</ul></li>
<li><p>To Estimate V</p>
<ul>
<li><img src="/images/image-20220209103037952.png" alt="image-20220209103037952" style="zoom:25%;"></li>
<li>V(U, A) = 1, V(U, B) = V(R1, B) or min(V(R1, B), T(U))</li>
</ul></li>
</ul></li>
</ul>
<h2 id="lec8-query-optimization2">Lec8 Query Optimization2</h2>
<ul>
<li>Another Type of Data Stats: Histograms</li>
</ul>
<h3 id="cost-models">Cost models</h3>
<ul>
<li>Number of disk IOs</li>
<li>Index search:
<ul>
<li><img src="/images/image-20220215102501137.png" alt="image-20220215102501137" style="zoom: 33%;">
<ul>
<li>If result are clustered, the cost of index search<img src="/images/image-20220215102553177.png" alt="image-20220215102553177" style="zoom: 33%;"></li>
</ul></li>
<li>L + : means first reach a leaf node, then use linked list of the leaf node
<ul>
<li>eg, p is " &gt;=100, and "</li>
</ul></li>
<li>If <u>s is high,</u> gonna read all the blocks anyway, so should not use index</li>
<li>If s is low, index will save some time to read some blocks not contain the target</li>
<li>For <strong>clustered</strong>, use index is always better no matter s is low or high
<ul>
<li><img src="/images/image-20220209111734076.png" alt="image-20220209111734076" style="zoom:50%;"></li>
</ul></li>
</ul></li>
<li>Cost Metrics: Disk IO, one IO for one block
<ul>
<li>selectivity <em>s</em></li>
<li>Example: the plan generate less data
<ul>
<li>product.type &amp; customer.country: do the selective one first</li>
</ul></li>
</ul></li>
<li>Common join methods:
<ul>
<li><strong>Iteration Join</strong>: if R1 only have fewer tuples, it's good
<ul>
<li>could load M blocks in RAM at a time</li>
<li><img src="/images/image-20220215103033175.png" alt="image-20220215103033175" style="zoom:50%;"></li>
<li>cost of write means the cost of output</li>
</ul></li>
<li><strong>Merge Join</strong>:
<ul>
<li>outputTuple: could have several matchs</li>
<li>cost: <img src="/images/image-20220215103218015.png" alt="image-20220215103218015" style="zoom:50%;"></li>
<li>If Ri is not sorted, can sort it in 4 B(Ri) IOs: split table into chunks fit into memory, and sort in memory (1 Pass data in and 1 Pass data out). Then merge then (2IO in + out).
<ul>
<li>if memomry &gt;= <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex" xmlns="http://www.w3.org/2000/svg" width="19.605ex" height="2.656ex" role="img" focusable="false" viewBox="0 -969 8665.4 1174"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msqrt"><g transform="translate(853,0)"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g><g data-mml-node="mo" transform="translate(0,109)"><path data-c="221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z"></path></g><rect width="888" height="60" x="853" y="849"></rect></g><g data-mml-node="mo" transform="translate(1963.2,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="mi" transform="translate(2685.4,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(3154.4,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3499.4,0)"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mi" transform="translate(3964.4,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(4430.4,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(4930.4,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(5415.4,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mi" transform="translate(5965.4,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(6465.4,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(6826.4,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7398.4,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(7901.4,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(8199.4,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g></g></g></svg></mjx-container></span> (N is number of tuples?)</li>
</ul></li>
</ul></li>
<li><strong>Join with index</strong>:
<ul>
<li>R1 join R2 on C</li>
<li><img src="/images/image-20220215103348253.png" alt="image-20220215103348253" style="zoom:50%;"></li>
<li>can be less IO if R1 sorted / clustered by C</li>
</ul></li>
<li><strong>Hash join</strong>: suppose hash table fits in memory
<ul>
<li>read IOs: B(R1) + B(R2)</li>
<li>Can be done by hashing both tables to a common set of buckets on disk</li>
<li>Hash join on disk: (the table is too big, can not fit in disk)
<ul>
<li>create files on disk with different range of hash keys</li>
<li>load each bucket and compare to merge</li>
<li>Hash cost: 4(B(R1) + B(R2)):</li>
<li>Trick: hash only (key, pointer to record) pairs
<ul>
<li>before dereferencing pointer, sort pointers to get</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li>Summary
<ul>
<li><img src="/images/image-20220209140617763.png" alt="image-20220209140617763" style="zoom:50%;"></li>
<li>use hash join only when one of the table is small (both big table, use merge join)</li>
</ul></li>
</ul>
<h3 id="cost-based-plan-selection">Cost-based plan selection</h3>
<ul>
<li>How to generate plans:
<ul>
<li>pick left-deep joins : left-deep join pros:
<ul>
<li>If R is small and use hash join, the intermidate result can always stored in memory, do not need to write out to disk.</li>
<li>Left-deep join can save IO: do not need to save intermediate table to a file. If left join use same kind of join (hash join, merge join)</li>
<li>could have n! plans using left-deep</li>
</ul></li>
<li>searching througth the most impactful decisions first</li>
</ul></li>
<li>How to prune plans:</li>
<li>Memoization and Dynamic programming:
<ul>
<li>mnay subplans will appear repeatedly</li>
<li>cache sub-tree of the query plan, save the cost estimation and statistics</li>
</ul></li>
</ul>
<h3 id="spark-sql">Spark SQL</h3>
<ul>
<li><p>Original Spark API: RDD</p>
<ul>
<li>RDDs: data is inmutable (can recovery from failure) , create a new one based on previous one</li>
<li>Cons:
<ul>
<li>functions pass in are arbitrary code: hard for engine to make optimization(don't know whether the function is commutive, associate)</li>
<li>Data stored is arbitrary object: can not do optimization using storage format (don't know the data is adjacent; do not have knowledge on storage)</li>
</ul></li>
</ul></li>
<li><p>DataFrame API: schema and offer relational operations</p>
<ul>
<li>DSL: domain specific language</li>
<li>DataFrames for integrating relational ops in Scala/Java/Python programs</li>
<li>What dataframed enable:
<ul>
<li>Compact binary representation</li>
<li>Optimization across operators (join reordering, predicate pushdown, etc)</li>
<li>Runtime code generation</li>
</ul></li>
<li>Based on data frame concept in R, Pandas
<ul>
<li>Spark is the first to make this declarative</li>
</ul></li>
<li>Integrated with the rest of Spark
<ul>
<li>ML library takes DataFrames as input/output</li>
<li>Easily convert RDDs ↔︎ DataFrames</li>
</ul></li>
</ul></li>
<li><p>Efficient library for working with structured data</p>
<ul>
<li><p>2 interfaces: SQL for data analysts and external apps,</p></li>
<li><p>DataFrames for complex programs</p></li>
</ul></li>
<li><p>Data sources:</p>
<ul>
<li>spark is a computer engine, do not know how to store data</li>
<li>support different format data source</li>
</ul></li>
</ul>
<h2 id="lec9-tanscations-and-failure-recovery1">Lec9 Tanscations and Failure Recovery1</h2>
<h3 id="spark-sql-wrap-up">Spark SQL Wrap-up</h3>
<ul>
<li>can migrate from different data source</li>
</ul>
<h3 id="defining-correctness">Defining Correctness</h3>
<ul>
<li>Integrity or Consistency Constraints
<ul>
<li>Constrains are boolean constrains</li>
<li>Consistent state: satisfies all constraints</li>
<li>Transcation constrains: can be emulated by simple boolean constraints</li>
</ul></li>
<li>Observation: DB can’t always be consistent!
<ul>
<li>So need transcation: Collection of Actions taht preserver Consistency</li>
</ul></li>
<li>Correctness: database is left consistent</li>
</ul>
<h3 id="transcation-model">Transcation model</h3>
<ul>
<li>Both clients and system can abort transcations
<ul>
<li>Why system abort? eg, system crash, state in memroy lost; eg, concurrency control</li>
</ul></li>
<li>How constrains can be violated?
<ul>
<li>transcation bug: read something and find that does not apply</li>
<li>DBMS bug (not consider here)</li>
<li>Hardward failure</li>
<li>Data sharing: 2 transactions can not see each other's intermediate result</li>
</ul></li>
</ul>
<h3 id="hardware-failures">Hardware failures</h3>
<ul>
<li>Failure models
<ul>
<li>desired events</li>
<li>Undesired Expected Events</li>
</ul></li>
<li>Models:
<ul>
<li>operations: Input(x), output(x), read(x, t) and write(x, t)
<ul>
<li>the read and write result will be put <u>in memory</u></li>
</ul></li>
</ul></li>
<li>Need Atomicity</li>
</ul>
<h3 id="recovery-with-logs">Recovery with logs</h3>
<ul>
<li><p>Solution: undo logging (aka immediate modification)</p>
<ul>
<li><p>write the old value to log; New value is in memory.</p></li>
<li><p><strong>When call output(A), first write a log entry &lt;T1, A , old_vale&gt;</strong></p></li>
<li><p>When commit, first write an entry &lt;T1, commit&gt;</p></li>
<li><p><img src="/images/image-20220312171600215.png" alt="image-20220312171600215" style="zoom:50%;"></p></li>
</ul></li>
<li><p>One complication: Keep log in memory</p>
<ul>
<li>Writing log (in disk) need a lot of IO. Need to keep log in memory and then write to disk.</li>
<li>Bad state #1: If we update reocrd A in disk before we write log to disk. After change disk record A from 8 to 16, memory crash. We do not know the old value.</li>
<li>Bad state #2: Write the whole log out to disk, after disk A change from 8 to 16, but before disk B change from 8 to 16. If crash here, we will think T1 has already commit, and do not need to modify A's value. However, the state on disk is not consistent.
<ul>
<li>Before commit, have to update all the data pages.</li>
</ul></li>
</ul></li>
<li><p>Rules for undo logging</p>
<ul>
<li>For every action, generate undo log record (containing old value)</li>
<li>Before X is modified on disk, log records pertaining to X must be on disk (“write ahead logging”: WAL)</li>
<li>Before commit record is flushed to log, all writes of transaction must be on disk</li>
</ul></li>
<li><p>Recovery Rules: Undo logging</p>
<ul>
<li><ol type="1">
<li>Let S = set of transactions with &lt;Ti, start&gt; in log, but no &lt;Ti, commit&gt; or &lt;Ti, abort&gt; in log</li>
</ol></li>
<li><ol start="2" type="1">
<li>For each &lt;Ti, X, v&gt; in log, in reverse order (<strong>latest to earliest</strong>), do</li>
</ol>
<ul>
<li>if Ti <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.09ex" xmlns="http://www.w3.org/2000/svg" width="1.509ex" height="1.312ex" role="img" focusable="false" viewBox="0 -540 667 580"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g></g></g></svg></mjx-container></span> S then
<ul>
<li>write (X, v) + output (X)</li>
</ul></li>
</ul></li>
<li><ol start="3" type="1">
<li>For each Ti <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.09ex" xmlns="http://www.w3.org/2000/svg" width="1.509ex" height="1.312ex" role="img" focusable="false" viewBox="0 -540 667 580"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g></g></g></svg></mjx-container></span> S do</li>
</ol>
<ul>
<li>write &lt;Ti, abort&gt; to log</li>
</ul></li>
</ul></li>
<li><p>Why can NOT read log from earliest to last?</p>
<ul>
<li>multiple write to same record, need to end up with the oldest value</li>
<li>eg: &lt;T1, x, 8&gt; &lt;T2, x, 12&gt; &lt;T3, x, 5&gt; &lt;abort, T1&gt;
<ul>
<li>undo logging is the old value.</li>
<li>expected x value is 8.</li>
<li>after recovery (add abort record), need to be &lt;T1, x, 8&gt; , &lt;T2, x, 12&gt; &lt;T3, x, 5&gt; &lt;abort, T3&gt; &lt;abort, T2&gt; &lt;abort, T1&gt;</li>
</ul></li>
<li>eg: write &lt;Ti, abort&gt; in step 3 should from latest to earliest.
<ul>
<li><img src="/images/image-20220312173802557.png" alt="image-20220312173802557" style="zoom:50%;"></li>
</ul></li>
</ul></li>
<li><p>Undo is idempotent.</p>
<ul>
<li>crash several times</li>
</ul></li>
<li><p>Any downside of undo logging?</p>
<ul>
<li>A lot of IO in "Before commit record is flushed to log, all writes of transaction must be on disk"
<ul>
<li>random IO</li>
</ul></li>
<li>might have a lot of redundant information in logging, if we modify a same record for several times</li>
<li>Hard to replicate the database across the network
<ul>
<li>mush push all changes across the network. Need to write twice the data (logging + data)</li>
</ul></li>
</ul></li>
</ul>
<h3 id="redo-logging">Redo logging</h3>
<ul>
<li><u>YOLO style</u>: if we have all the loggins on disk or especially &lt;T1, commit&gt; log write to disk, we have all the information need to. If not, we have nothing.</li>
<li>End, everything is on disk</li>
<li>Rules:
<ul>
<li>For every action, generate redo log record(containing <strong>new value</strong>)</li>
<li>Before X is modified on disk (in DB), <strong>all log records</strong> for transaction that modified X (including commit) must be on disk</li>
<li>Flush log at commit (keep all the values in memory)</li>
<li>Write END record after DB updates are flushed to disk</li>
</ul></li>
<li><img src="/images/image-20220312174753864.png" alt="image-20220312174753864" style="zoom:50%;"></li>
</ul>
<h2 id="lec10-guest-lecture1">Lec10 Guest Lecture1</h2>
<p>Abstractions for Machine Learning Compilations - Chen Tianqi</p>
<p>##Lec11 Tanscations and Failure Recovery2</p>
<h3 id="redo-logging-1">Redo logging</h3>
<ul>
<li>combinning &lt;T1, end&gt; records - optimize normal operation =&gt; checkpoints
<ul>
<li>a lot of transcations update a same record X</li>
<li>write a combined &lt; end&gt; record.</li>
</ul></li>
<li>checkpoints
<ul>
<li>What to do at recovery
<ul>
<li>find last checkpoint, do not need to read the privious logging</li>
<li>REDO all the commit record</li>
<li>for un-commited record, ignore it. It does not write the checkpoint/data page to disk, so we do not need to do anything</li>
</ul></li>
<li>Need to temporarily stop transactions, stop everything</li>
</ul></li>
<li>Redo logging need to keep all modified blocks in memory</li>
</ul>
<h3 id="undoredo-logging-undo-rdoe">Undo/Redo logging: Undo + Rdoe</h3>
<ul>
<li><p>Write more information: update = &lt;Ti, X, new X, old X&gt;</p></li>
<li><p>object can be flushed <strong>before or after</strong> Ti commits.</p>
<ul>
<li>log record must be flushed before corresponding data (WAL)</li>
<li>Flush log <u>up to commit</u> <u>record</u> at Ti commit</li>
</ul></li>
<li><p>Example:</p>
<ul>
<li><img src="/images/image-20220313163945365-7203985.png" title="fig:" alt="image-20220313163945365"></li>
<li>The A, B might on disk or not</li>
<li>REDO T1 (T1 committed), set A to 10, set B to 20</li>
<li>T2 un-committed: wirte out all the old values. UNDO all its update.
<ul>
<li>set C = 38, set D = 40 (in memory or disk ????)</li>
</ul></li>
</ul></li>
<li><p>Non-quiescent checkpoints:</p>
<ul>
<li>do not need to stop everything</li>
<li>Wirte start-ckpt, end-copt</li>
<li>Start-ckpt + active TXNs: when recovery, need to know where to go before the checkpoint. recovery these active txns</li>
<li>Algo: write every drity page to disk, and then write a</li>
<li>Examples 1:
<ul>
<li><img src="/images/image-20220313164700579.png" alt="image-20220313164700579" style="zoom:50%;"></li>
<li>start from latest logging (b) to (a), it is</li>
</ul></li>
<li>Example 2: commited REDO b and c,
<ul>
<li>A must be flush to disk</li>
<li>b and c might flush to disk, or might not</li>
<li><img src="/images/image-20220313164908353.png" alt="image-20220313164908353" style="zoom:50%;"></li>
</ul></li>
<li>Example 3: Never finished
<ul>
<li><img src="/images/image-20220313165153939.png" alt="image-20220313165153939" style="zoom:50%;"></li>
<li>UNDO (if not committed) &lt;T1,b&gt; &lt;T1, c&gt; since the flush to disk can happen before</li>
<li>REDO (if committed) &lt;T1,b&gt; &lt;T1, c&gt;</li>
</ul></li>
<li>If there is a commit between ckpt-start and ckpt-end, we only know the page before checkpoint-start will be flush to disk</li>
</ul></li>
<li><p>Algo: <strong>undo-un-commited; redo-commited</strong></p>
<ul>
<li><img src="/images/image-20220313165847534.png" title="fig:" alt="image-20220313165847534"></li>
<li>valid checkpoint: have both start and end</li>
</ul></li>
</ul>
<h3 id="external-actions">External Actions</h3>
<ul>
<li>can not undo a transfer money action
<ul>
<li>Execute real-world actions after commit</li>
<li>Try to make idempotent
<ul>
<li>Give each action a unique ID</li>
</ul></li>
</ul></li>
<li>How Would You Handle These Other External Actions?
<ul>
<li>Charge a customer's credit card: add a TXNid, if VISA find a repeated TXNid, ignore it.</li>
<li>Cancel hotel room: can repeatly do it, idempotent</li>
<li>Send data into a streaming system: put some unique id in each record, consumer will ignore the repeated one</li>
</ul></li>
</ul>
<h3 id="media-failuredisk-failure">Media Failure(disk failure)</h3>
<ul>
<li><p>Redundante Storage</p>
<ul>
<li>Output(X) → three outputs</li>
<li>Input(X) → three inputs + vote</li>
</ul></li>
<li><p>Another way: log-Based Backup</p>
<ul>
<li><p>Backup database</p>
<ul>
<li><p>Create backup database: Need to write DB dump</p>
<p><img src="/images/image-20220313180008953.png" alt="image-20220313180008953" style="zoom:50%;"></p></li>
</ul></li>
<li><p>When Can logs Be Discarded? Before the last needed undo before DB dump</p>
<ul>
<li><img src="/images/image-20220313180348178.png" alt="image-20220313180348178" style="zoom:50%;"></li>
</ul></li>
</ul></li>
</ul>
<h2 id="lec12-concurrency">Lec12 Concurrency</h2>
<ul>
<li><p>Different transcations need to access same item at same time - might violate constrain</p></li>
<li><p>Define isolation levels: (defined by anomalies)</p>
<ul>
<li>Serializability: result is same as some serial schedule (strongest)</li>
<li>Read uncommitted</li>
<li>Read committed</li>
<li>Repeated Read</li>
<li>Serialzable</li>
</ul></li>
<li><p>Anomolies:</p>
<ul>
<li><p>Dirty Reads</p></li>
<li><p>Unrepeatable Reads,</p></li>
<li><p>Phantom Reads</p></li>
</ul></li>
</ul>
<h3 id="what-makes-a-schedule-serializable">What makes a schedule serializable?</h3>
<ul>
<li>only look at order of read &amp; write</li>
<li>Do not have assumption on the transcations</li>
<li>Is a schedule serializable?
<ul>
<li>swap things and try to see</li>
</ul></li>
<li>Another way to do:
<ul>
<li><img src="/images/image-20220313211112459.png" alt="image-20220313211112459" style="zoom:50%;"></li>
<li>read1(B) after write2(B): T2-&gt; T1</li>
<li>dependency graph</li>
</ul></li>
</ul>
<h3 id="conflict-serializability">Conflict serializability</h3>
<ul>
<li><p>conflicting actions: from different transcations</p></li>
<li><p>Write takes a lot of time =&gt; but assumption: serialize</p></li>
<li><p>Conflict equivalent:</p>
<ul>
<li>only change the order from different transcations</li>
</ul></li>
<li><p>Conflict serializable: Conflict serializable means there exists at least one serial execution with same effects</p></li>
</ul>
<h3 id="precedence-graphs">Precedence graphs</h3>
<ul>
<li><p>check whether a schedule is conflict seriablizable</p></li>
<li><p>Edges:</p>
<ul>
<li><img src="/images/image-20220313211922425.png" alt="image-20220313211922425" style="zoom:50%;"></li>
</ul></li>
<li><p>Conflicts: W1R2/ R1W2 /W1W2 =&gt; need an edge from 1-&gt;2</p></li>
<li><p>S1, S2 is conflict equivalent =&gt; P(S_1) = P(S_2)</p></li>
<li><p>P(S1) is acyclic, &lt;=&gt; S1 conflict serializable</p>
<ul>
<li>topo ordering</li>
</ul></li>
</ul>
<h3 id="enforce-serializability-via-2-phase-locking">Enforce serializability via 2-phase locking</h3>
<ul>
<li><p>Shared and exclusive locking</p></li>
<li><p>Well-Formed Transcations:</p>
<ul>
<li>transcation need to lock the item before (read or write)</li>
<li>L1(A):</li>
<li>U1(A): the transcation is locked</li>
</ul></li>
<li><p><img src="/images/image-20220313213706703.png" alt="image-20220313213706703" style="zoom:50%;"></p>
<ul>
<li>S1 is not legal, L2(B) is not well-formed</li>
</ul></li>
<li><p>Rules:</p>
<ul>
<li><p>Rule1: Well-Formed Transactions: lock and unlock</p></li>
<li><p>Rule2: Legal Scheduler: only one can lock</p></li>
<li><p>Rule3: 2-Phase Locking: growing + Shrinking</p>
<ul>
<li><p>only unlock when commit</p></li>
<li><p>if T1 knows it will not use lock of A anymore, could unlock A here: (if the transcation manager is smart enough)</p>
<ul>
<li>Get all the locks, before release on of the lock</li>
<li>still 2-phase locking</li>
</ul>
<figure>
<img src="/images/image-20220313214211984.png" alt="image-20220313214211984"><figcaption aria-hidden="true">image-20220313214211984</figcaption>
</figure></li>
</ul></li>
</ul></li>
<li><p>Dead lock:</p>
<ul>
<li>Detect and roll back</li>
<li>Agree on an order to lock items: if need to get Lock A and lock B, need to get lock A first.</li>
</ul></li>
<li><p>Conflict Rules for lock ops:</p>
<ul>
<li>conflict: &lt;Li (A), Lj(A)&gt; , &lt;Li(A), Uj(A)&gt;</li>
<li>no conflict:&lt;ui(A), uj(A)&gt;, &lt;l<strong>i</strong>(A), r<strong>j</strong>(A)&gt;</li>
</ul></li>
<li><p>Shrink(Ti) = SH(Ti)</p>
<ul>
<li><img src="/images/image-20220313215445599.png" title="fig:" alt="image-20220313215445599"></li>
<li>Ti -&gt; Tj means that shrink T_i happens before shrink T_j</li>
</ul></li>
<li><p>Theorem: Rules #1,2,3 =&gt; Conflict Serializable Schedule</p></li>
<li><p>Use locking to make sure others say the changes after you totally finish that</p></li>
<li><p>Conflict Serializable:</p>
<ul>
<li>2PL is a subset of conflict serializable</li>
<li>Some example si conflict serializable, but not 2PL
<ul>
<li><img src="/images/image-20220313225336564.png" alt="image-20220313225336564" style="zoom:50%;"></li>
</ul></li>
</ul></li>
</ul>
<h2 id="lec13-concurrency2">Lec13 Concurrency2</h2>
<h3 id="pl">2PL</h3>
<ul>
<li><p>how to implement 2PL</p>
<ul>
<li>don't ask user/transcations to request/release locks</li>
<li>Hold all locks until a transcation commits</li>
</ul></li>
<li><p>Shared Locks</p>
<ul>
<li>Shared mode lock, any number of transcations can read it, but can not write it</li>
<li>S: share ; X: exclusive</li>
<li>Rule1: Well-formed TXNs:
<ul>
<li>option1: always use X lock</li>
<li>option2: get low level lock first, update to X on write</li>
</ul></li>
<li>Rule2: Legal Scheduler:
<ul>
<li>for S mode: no one else can have a X lock, but could have S</li>
<li>for X mode: no S and no X</li>
</ul></li>
<li>Rule3: 2PL:
<ul>
<li>allow upgrades from S to X only in growing phase</li>
</ul></li>
<li><img src="/images/image-20220313231247318.png" alt="image-20220313231247318" style="zoom:50%;"></li>
</ul></li>
<li><p>Other kind of locks:</p>
<ul>
<li><p>increment locks:</p>
<ul>
<li><p>Atomic add: IN_i(A) = {read(A); A &lt;- A+ k; write()}</p></li>
<li><p>Increment locks: compatibility Matrix, commutable</p>
<figure>
<img src="/images/image-20220313231213191.png" alt="image-20220313231213191"><figcaption aria-hidden="true">image-20220313231213191</figcaption>
</figure></li>
</ul></li>
<li><p>Update locks</p>
<ul>
<li>X and S mode can easy to cause deadlocks</li>
<li>A common case for dead lock:
<ul>
<li><img src="/images/image-20220313231532103.png" title="fig:" alt="image-20220313231532103"></li>
</ul></li>
<li>Update mode lock: lock on {read(A), write(A)}
<ul>
<li><img src="/images/image-20220313231748732.png" alt="image-20220313231748732" style="zoom:50%;"></li>
<li>Asymmetric table!</li>
<li>Since we want to update, so we donot want other to read it (can not request a new shared lock)</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Which objects do we lock?</p>
<ul>
<li>Can do it in different level at same time</li>
<li>T1(IS) means TXN1 might need part or all of the data in the table
<ul>
<li>eg, T1(S) might</li>
</ul></li>
<li>T2(S) means T2 want to read whole table</li>
<li><img src="/images/image-20220313233233465.png" alt="image-20220313233233465" style="zoom:50%;">
<ul>
<li>should NOT allow this, we do not know the</li>
</ul></li>
</ul></li>
<li><p>multiple granularity locks</p>
<ul>
<li>IS: intend to share, and will use S lock the lower level child (T1(S))</li>
<li>IX: intend to update, and will use X lock at lower level child</li>
<li>SIX: want to read anywhere in the table, but only update few records</li>
<li><img src="/images/image-20220313233533795.png" title="fig:" alt="image-20220313233533795"></li>
<li><img src="/images/image-20220313234329245.png" title="fig:" alt="image-20220313234329245"></li>
</ul></li>
<li><p>3 levels: Relation - tuples - fields</p>
<ul>
<li>Exercise1: Yes, T2(IX), T2(IX), T2(X)</li>
<li>Exercise2: Not allowed, need to wait</li>
<li>Exercise3: T2(IX), T2(IX), T2(X)</li>
<li>Exercise4: Yes, T2(IS), T2(IS), T2(S)</li>
<li>Exercise5: Not, T1 could be reading from anything</li>
</ul></li>
<li><p>Insert + Delete operations</p>
<ul>
<li>problem: phantoms</li>
<li>two TXNs insert new record with same ID</li>
<li>Solution: use multiple granularity tree <img src="/images/image-20220314001544012.png" alt="image-20220314001544012"></li>
<li>Will not work if the constrain is about multiple tables</li>
</ul></li>
<li><p>Instead lock the whole table R, could locking some range</p></li>
</ul>
<h3 id="optimistic-concurrency-validation">Optimistic concurrency / validation</h3>
<ul>
<li>validation：
<ul>
<li>3 Phases:
<ul>
<li>Read (write to temporary storage)
<ul>
<li>no locking, very fast</li>
</ul></li>
<li>validation (check whether schedule so far is serializable)
<ul>
<li>all in database, do not need to wait for user input/networking, much faster</li>
</ul></li>
<li>write(write to DB)</li>
</ul></li>
<li>If the validation order is T1, T2, T3, …, then resulting schedule will be conflict equivalent to Ss = T1, T2, T3, …</li>
</ul></li>
<li>Implementing Validation:
<ul>
<li>FIN: TXNs finish phase3</li>
<li>VAL: finish phase2 and still writing to DB</li>
</ul></li>
<li>Example that validation must prevent
<ul>
<li>RS: read set</li>
<li>WS: write set</li>
<li><img src="/images/image-20220314101442744.png" alt="image-20220314101442744" style="zoom:50%;">
<ul>
<li>If t3 started, could read A and B but t2 is trying to update B</li>
<li>If t2 finished before T3 start, it will be fine</li>
</ul></li>
<li><img src="/images/image-20220314101723263.png" alt="image-20220314101723263" style="zoom:50%;">
<ul>
<li>get a old value of D. Between validate, can flush data to disk</li>
<li>T2 finished before T3 validate start, it's OK</li>
</ul></li>
</ul></li>
<li>Validation Rule:
<ul>
<li><img src="/images/image-20220314102017905.png" title="fig:" alt="image-20220314102017905">
<ul>
<li>ignore set: remeber a ignore set, everything finish before it, just remeber what finish before me.</li>
<li>FIN: set of finished TXNs (abort or commit.)</li>
<li>VAL: validation set, a set of TXNs might conflict with Tj (and is writing to disk)</li>
</ul></li>
<li>Check:
<ul>
<li><img src="/images/image-20220314102036192.png" title="fig:" alt="image-20220314102036192"></li>
<li>only have 2 bad cases.</li>
</ul></li>
<li>Exercise:
<ul>
<li><img src="/images/image-20220314102815028.png" alt="image-20220314102815028" style="zoom:50%;"></li>
<li>U validate: it can validate. cause no one have write or read something</li>
<li>T validate: Yes.</li>
<li>V validate: Yes. V is reading B, no one else is writing B but hasn't finish. V is wiriting D and E, TXN U might conflict with it but U has already finished.</li>
<li>W: No. It's reading D, but V will write D and has not finished yet.</li>
</ul></li>
</ul></li>
<li>Is vaidation = 2PL?
<ul>
<li>Validation is a subset of 2PL</li>
<li><img src="/images/image-20220314123016482.png" alt="image-20220314123016482" style="zoom:50%;"></li>
</ul></li>
<li>When to use Validation:
<ul>
<li>Validation perfoms better than locking</li>
</ul></li>
</ul>
<h2 id="lec14-concurrency3-and-distributed-databases">Lec14 Concurrency3 and Distributed databases</h2>
<h3 id="concurrency-control-recovery">Concurrency Control &amp; Recovery</h3>
<ul>
<li><p>Abort:</p>
<ul>
<li>Non-presistent commit:
<ul>
<li>can be avoided by recoverable schedules</li>
<li>Example1: do not allow Tj commit before Ti</li>
</ul></li>
<li>Cascading rollback:
<ul>
<li>can be avoided by ASR (avoids-cascading-rollback (ACR))</li>
<li>example</li>
</ul></li>
<li><img src="/images/image-20220318141844024.png" alt="image-20220318141844024" style="zoom:50%;"></li>
</ul></li>
<li><p><strong>reads from</strong></p>
<ul>
<li><img src="/images/image-20220317231734205.png" title="fig:" alt="image-20220317231734205"></li>
<li>Tj is the last write to A</li>
<li>ai: transcation Ti aborts</li>
</ul></li>
<li><p>Recoverable</p>
<ul>
<li><img src="/images/image-20220317232052289.png" alt="image-20220317232052289" style="zoom:50%;"></li>
</ul></li>
<li><p>How to archieve recoverable schedule</p>
<ul>
<li>Strict 2PL: hold write locks (X lock) until commit</li>
<li>For validation, no change, it's recoverable
<ul>
<li>validation point is the commit point</li>
</ul></li>
</ul></li>
<li><p>Definations:</p>
<ul>
<li>recoverable:if each tx commits only after all txs from which it read have committed</li>
<li>S <strong>avoids</strong> <strong>cascading rollback</strong> if each tx may read only values written by committed txs, <u>can writing to record while others are writing</u></li>
<li>S is <strong>strict</strong> if each tx may read and write only items previously written by committed txs (≡ strict 2PL)</li>
</ul></li>
<li><p>Examples:</p>
<ul>
<li>recoverable: T2 read from T1, t2 can only commit after t1
<ul>
<li>does not avoid cascading rollback</li>
</ul></li>
</ul></li>
<li><p>Recoverability &amp; serializability:</p>
<ul>
<li>every strict schedule is seriablizable</li>
</ul></li>
<li><p>Weaker isolation levels</p>
<ul>
<li>Dirty reads (weakest): equivalent to having long-duration write locks, but no read locks</li>
<li>Read committed: have long-duration write locks(X) and short-duration read locks(S)
<ul>
<li>you read a object, then release S lock, others get X lock and write then release, you re-get the S lock and read.</li>
</ul></li>
<li>Repeatable reads:
<ul>
<li>phantoms: if 2 TXNs want to insert record at same time, might violate some constriants, like ID need to be unique</li>
</ul></li>
<li>Serializable</li>
<li>Snapshot isolation: always see the snapshot when it starts
<ul>
<li>MVCC, like git. But git merge some times can not compile</li>
<li>not serializable. Example: txns write different valud</li>
</ul></li>
</ul></li>
</ul>
<h3 id="distributed-databases">Distributed databases</h3>
<ul>
<li>Why distribute DB
<ul>
<li>replication: many nodes, fault recovery</li>
<li>partitioning: parallel, complete faster</li>
</ul></li>
<li><strong>Replication</strong> Strategies:
<ul>
<li>how to read/write to data on multiple nodes</li>
<li>Method1: primary-backup
<ul>
<li>send all the request to primary, forward the operation or log to backup</li>
</ul></li>
<li>Method2: Quorum Replication
<ul>
<li>each read and write goes to more than half of nodes, majority</li>
<li>What if we don't have intersection
<ul>
<li>eventual consistency</li>
<li>asychronously broadcast all writes to all replicas</li>
</ul></li>
<li>When is this acceptable
<ul>
<li>only write once, immutable</li>
<li>update photo to</li>
</ul></li>
</ul></li>
<li>How many replicas:
<ul>
<li>support F failures, F+1</li>
<li>3*F + 1</li>
</ul></li>
<li>Solution to failure:
<ul>
<li>Distributed computing: use consensus</li>
</ul></li>
<li>Consensus: distributed agreement</li>
</ul></li>
<li><strong>Partitioning</strong> strategies
<ul>
<li>partition record into multiple server</li>
<li>Hash key to servers</li>
<li>Partition keys by range
<ul>
<li>keys stored contiguously</li>
<li>do range query more efficiently</li>
<li>store a table, map from range to server id</li>
</ul></li>
</ul></li>
<li>Distributed transcations
<ul>
<li>need cross-partition concurrency control</li>
</ul></li>
<li>Atomic commitment
<ul>
<li>problem: abort</li>
<li>Why one node want to abort but others do not want
<ul>
<li>another client write to part of the nodes, make it need to abort</li>
<li>one node crash</li>
<li>have deadlock between nodes</li>
</ul></li>
<li>Two-Phase Commit: solve the abort problem
<ul>
<li>each TXNs need a coordinator</li>
<li>before commit, send prepare messge to each participant</li>
<li>everyone prepare: commit: Participant need to reply 2 messages
<ul>
<li><img src="/images/image-20220318154340032.png" alt="image-20220318154340032" style="zoom:33%;"></li>
</ul></li>
<li>one partition abort: abort
<ul>
<li><img src="/images/image-20220318154411952.png" alt="image-20220318154411952" style="zoom:33%;"></li>
</ul></li>
</ul></li>
<li>2PC + Validation
<ul>
<li>need to block between prepare and commit</li>
<li>validation is fast, can get fast response</li>
</ul></li>
<li>2PC + 2PL</li>
<li>2PC + logging:
<ul>
<li>log before reply <code>prepare</code></li>
<li>log before commit</li>
</ul></li>
</ul></li>
</ul>
<h2 id="lec15-distributed-databases2">Lec15 Distributed databases2</h2>
<ul>
<li>Assumption: all the nodes will come back after a crach eventually</li>
</ul>
<h3 id="two-phase-commit-2pc">two-phase commit (2PC)</h3>
<ul>
<li>What could go wrong:
<ul>
<li>don't hear back from a server</li>
<li>coordinator unavailable
<ul>
<li>select a new coordinator</li>
</ul></li>
<li>both server and coordinator goes way?
<ul>
<li>rest of partiction must wait</li>
</ul></li>
</ul></li>
<li>Coordination is Bad new, every atomic commitment protocol is blocking</li>
<li><img src="/images/image-20220318154005906.png" alt="image-20220318154005906" style="zoom:50%;"></li>
</ul>
<h3 id="cap-theorem">CAP Theorem</h3>
<ul>
<li><p>Assumption: Asynchronous Network Model</p>
<ul>
<li>message can be arbitrarily delayed</li>
<li>can not distinguish between delayed message and failed nodes</li>
</ul></li>
<li><p>Distributed system can choose CP(Consistency) or AP(Availability)</p>
<ul>
<li>can not have both</li>
</ul></li>
<li><p>have consistency is expensive</p>
<ul>
<li>lost availability</li>
<li>need to talk/comminicate between nodes</li>
<li>Multi-Datacneter Transcations:
<ul>
<li>44 ms apart, maximum 22 conflicting txns per second</li>
</ul></li>
</ul></li>
<li><p>Do we have to coordinate</p></li>
<li><p>Avoding coordination</p>
<ul>
<li>BASE = “Basically Available, Soft State, Eventual Consistency”</li>
<li>helpful ideas:
<ul>
<li>idempotent operations: if the update background program crash, then start, need same result if we do it twice</li>
<li>commutative operations</li>
</ul></li>
</ul></li>
<li><p>Example weak consistency model:</p>
<ul>
<li>Causal consistency</li>
<li>Example: the order of receive message and log is not same.
<ul>
<li>see the message then reply</li>
<li>receiver can receive message at different time</li>
</ul></li>
</ul></li>
</ul>
<h3 id="parallel-execution">Parallel execution</h3>
<ul>
<li><p>read-only / analysis dataset</p></li>
<li><p>Amdahl's law</p></li>
<li><p>Example: Distributed joins</p>
<ul>
<li><p>Algo1: shuffle hash join, Communication cost (N-1)/N (|A|+|B|)</p></li>
<li><p>Algo2: broadcast join on B, communication cost: (N-1)|B|</p></li>
<li><p>broadcast join is much faster if |B| &lt;&lt; |A|</p></li>
</ul></li>
<li><p>Handling imbalance</p>
<ul>
<li>Load balance dynamically at runtime</li>
</ul></li>
<li><p>Handling faults and stragglers</p>
<ul>
<li>fault recovery: (run time)
<ul>
<li>simple recovery: use checkpoints, runtime grows with N (N nodes)</li>
<li>parallel recovery: redistribute its task to others, runtime T/(1-f), doesn't grow with N</li>
</ul></li>
</ul></li>
<li><p>Summary: Parallel = communication cost; load balance; fault recovery</p></li>
</ul>
<h2 id="lec16-cloud-database-systems">Lec16 Cloud Database systems</h2>
<ul>
<li>SaaS, PaaS, IaaS(Infra)</li>
<li>S3 &amp; Dynamo: key-value stores
<ul>
<li>Consistency: eventual consistency</li>
<li>can only operate on one key</li>
<li>consistency: evental consistency, read-your-own-writes for new PUT</li>
<li>negtive caching for <code>not found</code></li>
<li>read-after-write: for one client</li>
</ul></li>
<li>Dynamo implementation (object stores)
<ul>
<li>commodity nodes, form a ring to split up the key among them
<ul>
<li>each node chose multiple position on the ring</li>
</ul></li>
<li>3 nodes, write to 2, read from 2: strong consistency</li>
</ul></li>
<li>Aurora: <strong>transcational</strong> database managed by cloud vender
<ul>
<li>only replicate redo log, compute the pages in the server</li>
</ul></li>
<li>BigQuery: <strong>analytical</strong> DBMS
<ul>
<li>separate compute and storage</li>
<li>elastic, faster</li>
<li>challenges: UDF, scheduling, indexing</li>
</ul></li>
<li>Delta Lake: ACID over object store
<ul>
<li>build as a client libarary</li>
<li>Just store objects on S3
<ul>
<li>hard to insert multiple objects at once</li>
<li>poor peformance</li>
</ul></li>
<li>implement a transaction log for each transction
<ul>
<li>periodical checkpoints</li>
<li>put data statistics in the check_point</li>
</ul></li>
</ul></li>
</ul>
<h2 id="lec17-guest-lecture2">Lec17 Guest Lecture2</h2>
<h2 id="lec18-streaming-systems">Lec18 Streaming Systems</h2>
<ul>
<li><p>compute queries on streaming data continuously (efficiently update result)</p></li>
<li><p>Example Query2 problem:</p>
<ul>
<li>user have some plan then change plan</li>
<li>need the user plan status when they visit the page</li>
</ul></li>
<li><p>Streaming Query Semantics</p>
<ul>
<li><p>processing_time: time arrives</p></li>
<li><p>event_time: thing happens</p></li>
<li><p>Tuples may be out-of-order in event time!</p></li>
<li><p>What if records keep arriving really late?</p>
<ul>
<li><p>not know our query is true or not</p></li>
<li><p>Solution: Bounding Event Time Skew</p>
<ul>
<li><p>max delay</p></li>
<li><p>watermarks: things older than this can be dropped;</p>
<p>track event times currently being processed and set the threshold based on that</p></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>CQL:</p>
<ul>
<li><img src="/images/image-20220318104013758.png" alt="image-20220318104013758" style="zoom:50%;"></li>
<li>stream-to-Relation: windows</li>
<li>relation-to-stream: <code>ISTREAM</code>, <code>DSTREAM</code>,<code>RSTREAM</code></li>
<li>When do stream&lt;=&gt; relation interaction happens:
<ul>
<li>every relation has a new version at each processing time</li>
</ul></li>
<li>When does the system write ouput
<ul>
<li>at each processing time</li>
<li>want triggers ofr when to output</li>
</ul></li>
</ul></li>
<li><p>Google Dataflow model</p>
<ul>
<li>windowing</li>
<li>trigger</li>
<li>incremental</li>
<li>example with water mark
<ul>
<li><img src="/images/image-20220318123909690.png" alt="image-20220318123909690" style="zoom:50%;"></li>
</ul></li>
</ul></li>
<li><p>Spark Structured Streaming</p>
<ul>
<li>Append output mode</li>
</ul></li>
<li><p>Outputs to other systems</p>
<ul>
<li>fault recovery:
<ul>
<li>transaciton approach</li>
<li>At-least-once approach</li>
</ul></li>
</ul></li>
<li><p>Query Planning &amp; execution</p>
<ul>
<li>streaming operators</li>
<li>Query planning: incrementalize a SQL query</li>
<li>Fault Tolerance: need to log
<ul>
<li>outputted ,read ,state</li>
<li>must log what we read at each proc. time before output for the proc. time</li>
<li>log operator state asynchronously</li>
</ul></li>
<li>example structured streaming
<ul>
<li><img src="/images/image-20220318124905196.png" alt="image-20220318124905196" style="zoom:50%;"></li>
</ul></li>
</ul></li>
<li><p>Parallel processing</p>
<ul>
<li><img src="/images/image-20220318125041356.png" title="fig:" alt="image-20220318125041356"></li>
</ul></li>
</ul>
<h2 id="lec19-security-and-data-privacy">Lec19 Security and data privacy</h2>
<ul>
<li><p>Security requirements</p>
<ul>
<li>Some security goals
<ul>
<li>authentication + authorization + auditing</li>
<li>confidentiality, integrity, privacy</li>
</ul></li>
<li>Thread models</li>
<li>useful building blocks:
<ul>
<li>encryption</li>
<li>cryptographic hash functions</li>
<li>secure channels, egTLS</li>
</ul></li>
</ul></li>
<li><p>Differenctial privacy</p>
<ul>
<li>user talk to database server</li>
<li>how to define privacy is difficult</li>
<li>differential privacy:
<ul>
<li>inject some answer, potential random result</li>
<li>A and B are two different dataset:</li>
<li><img src="/images/image-20220318130935738.png" alt="image-20220318130935738" style="zoom:33%;"></li>
<li><img src="/images/image-20220318131244768.png" alt="image-20220318131244768" style="zoom:33%;"></li>
</ul></li>
<li>properties:
<ul>
<li>composition: Adversary’s ability to distinguish DBs A &amp; B grows in a bounded way with each query</li>
<li>Parallel composition:</li>
<li>Easy to compute</li>
</ul></li>
<li>Computing Differential privacy bounds:
<ul>
<li>COUNT()</li>
<li>AVERAGE()</li>
</ul></li>
<li>Sensitivity</li>
<li>stability: set difference
<ul>
<li><img src="/images/image-20220318133444931.png" alt="image-20220318133444931" style="zoom:50%;"></li>
<li>change the key, one group will decrease 1 and another will increase 1</li>
</ul></li>
<li>Partition Operator</li>
<li>PINQ</li>
</ul></li>
<li><p>Other security tools</p>
<ul>
<li>computing on encrypted data
<ul>
<li>limitation: see relative frequency of keys</li>
</ul></li>
<li>Hardware Enclaves</li>
<li>Multi-Party Computation
<ul>
<li>eg, Secret Sharing</li>
<li>performance is quite fast: just addtions</li>
<li>Funciont Secret Sharing</li>
</ul></li>
<li>Lineage Tracking and retraction</li>
</ul></li>
</ul>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><em></em><a class="button is-default" href="/blog/posts/b01ff30b" title="CS231A-Notes"><span class="has-text-weight-semibold">Next: CS231A-Notes</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="Haojen/Claudia-theme-blog" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/wwwjn"><i class="iconfont icon-github"></i></a><!-- Ins--><!-- RSS--><!-- 知乎--><!-- 领英--><a title="linkedin" target="_blank" rel="noopener nofollow" href="//www.linkedin.com/in/wangjiani"><i class="iconfont icon-linkedin"></i></a><!-- 脸书--></section><p><span>Copyright ©</span><span> Jiani Wang 2022</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/blog/js/post.js"></script></body></html>