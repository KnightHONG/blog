<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>CS224W:Which Trick Works Best in GNN?</title><meta name="description" content="Be my beacon X.K."><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.png"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="Which Trick Works Best in GNN?— Analyzed on arXiv Citation Dataset

By Yezhen Cong, Kaili Huang, Jiani Wang as part of the Stanford CS224W course project.

Overview
For students and researchers, reading papers is very helpful when they are studying certain topics. As you can see on the paper archive website arXiv, papers are categorized into different subj.."><meta name="generator" content="Hexo 5.4.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Jiani Wang's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">CS224W:Which Trick Works Best in GNN?</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Click back to the top</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">blog</a></h3><h3 class="is-inline-block"><a href="/about">Home</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">blog</a></h3><h3 class="is-inline-block"><a href="/about">Home</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#which-trick-works-best-in-gnn-analyzed-on-arxiv-citation-dataset"><span class="toc-text">Which Trick Works Best in GNN?— Analyzed on arXiv Citation Dataset</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#overview"><span class="toc-text">Overview</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#dataset-introduction"><span class="toc-text">Dataset Introduction</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#gat-graph-attention-network"><span class="toc-text">GAT (Graph Attention Network)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#tricks"><span class="toc-text">Tricks</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#enrich-node-features-with-node2vec-embeddings"><span class="toc-text">Enrich node features with Node2Vec embeddings</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#gat-variant"><span class="toc-text">GAT Variant</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#label-usage"><span class="toc-text">Label Usage</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#correct-and-smooth"><span class="toc-text">Correct and Smooth</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#self-kd"><span class="toc-text">Self-KD</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#experiments"><span class="toc-text">Experiments</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#training-process"><span class="toc-text">Training Process</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#results"><span class="toc-text">Results</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#conclusion"><span class="toc-text">Conclusion</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#references"><span class="toc-text">References</span></a></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/CS224W"><i class="tag post-item-tag">CS224W</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">CS224W:Which Trick Works Best in GNN?</h1><time class="has-text-grey" datetime="2022-01-11T01:44:02.000Z">2022-01-10</time><article class="mt-2 post-content"><h1 id="which-trick-works-best-in-gnn-analyzed-on-arxiv-citation-dataset">Which Trick Works Best in GNN?— Analyzed on arXiv Citation Dataset</h1>
<blockquote>
<p>By Yezhen Cong, Kaili Huang, Jiani Wang as part of the Stanford CS224W course project.</p>
</blockquote>
<h1 id="overview">Overview</h1>
<p>For students and researchers, reading papers is very helpful when they are studying certain topics. As you can see on the paper archive website <a target="_blank" rel="noopener" href="https://arxiv.org/">arXiv</a>, papers are categorized into different subjects (e.g., Physics, Mathematics, etc) and categories (e.g. Artificial Intelligence, Computational Geometry, etc) to facilitate research work. However, given a large number of papers, it’s very demanding to assign these categorical labels manually.</p>
<p>As we know, papers that cite each other often belong to similar topics. By connecting numerous papers according to their citation relationships, we can get a citation network, and therefore can apply Graph Neural Networks (GNN) to predict the categories of the unknown papers.</p>
<p>This blog aims to solve the problem of predicting the different subject areas of arXiv CS papers. When we were exploring top methods on the <a target="_blank" rel="noopener" href="https://ogb.stanford.edu/docs/leader_nodeprop/#ogbn-arxiv">OGB leaderboard</a>, we found there were some commonly used tricks on node classification tasks. So we approached the arXiv paper classification task by adding tricks step by step and illustrating the effectiveness of different tricks. In this blog, you will experience the process of building a state-of-the-art GNN model to solve a real-world problem by first constructing a base Graph Attention Network (GAT) and gradually adding tricks. We will introduce to you the principle and implementation of commonly used tricks in GNN and analyze their effectiveness with experimental results.</p>
<p>Please follow this <a target="_blank" rel="noopener" href="https://colab.research.google.com/drive/1aXHgXTU1mukt5Z5R7bR8jj8CQHc9iUVq">Colab Notebook</a> if you are interested in reproducing our experiments.</p>
<h1 id="dataset-introduction">Dataset Introduction</h1>
<p>The ogbn-arxiv dataset serves as a good example of a citation network. This dataset comes from Microsoft Academic Graph (MAG) [1], and represents the computer science (CS) arXiv paper citation network. As the figure shows, each node refers to an arXiv paper and each directed edge indicates one citation.</p>
<figure>
<img src="../images/1*j12WBNry4YUdmMBobEOuhQ.png" alt="ogbn-arxiv dataset (All figures in this blog are made by our team except those explicitly cites the sources)"><figcaption aria-hidden="true">ogbn-arxiv dataset (All figures in this blog are made by our team except those explicitly cites the sources)</figcaption>
</figure>
<p>Each paper comes with a feature vector, publication year, title, and abstract. The feature vectors are computed by first calculating the word embeddings over the MAG corpus with the skip-gram model [2] and then averaging over each paper’s title and abstract. The publication years range from 1971 to 2020.</p>
<p>The dataset comes with manually annotated labels and proposes the task of predicting 40 categories of arXiv CS papers, e.g., cs.AI (Artificial Intelligence), cs.LG (Machine Learning), cs.OS (Operating Systems). The metric is classification accuracy.</p>
<p>Given the goal of predicting recent papers’ areas based on historical data, papers published until 2017 are used for training, while those published in 2018 are used for validating and those published since 2019 are for testing.</p>
<h1 id="gat-graph-attention-network">GAT (Graph Attention Network)</h1>
<p>As a classical Graph Neural Network (GNN)[3], Graph Attention Network (GAT) [4] can be decomposed into two components as other GNNs: (1) Message (2) Aggregation. Initially, each node is assigned a node feature, which in our dataset is the paper’s feature vector. In a network that consists <em>L</em> GNN layers, at each layer <em>l</em> (<em>1, 2, …, L</em>), each node first calculates its own “message” with a message function, and then every node updates its node feature by aggregating the “messages” from all its neighbor nodes as well as itself. The Message and Aggregation steps can be concluded as below:</p>
<figure>
<img src="../images/1*EtsWfX972MpYzpmJyYpJPw@2x.png" alt="Message Step, h is the node feature, N(v) is the set of node v’s neighbor nodes, MSG is a function and it can be a neural network"><figcaption aria-hidden="true">Message Step, h is the node feature, N(v) is the set of node v’s neighbor nodes, MSG is a function and it can be a neural network</figcaption>
</figure>
<figure>
<img src="../images/1*5RWFfORm1sh6KaBNq4zSSA.png" alt="Aggregate Step, AGG is a function such as MEAN, MAX, SUM"><figcaption aria-hidden="true">Aggregate Step, AGG is a function such as MEAN, MAX, SUM</figcaption>
</figure>
<p>GAT, in addition, applies an extra self-attention mechanism to GNN. At the Aggregation step, the “message” of neighbor nodes are aggregated with respect to an “attention score”. For a central node <em>A</em> and one of its neighbor node <em>B</em>, an attention score <em>α</em> between <em>A</em> and <em>B</em> is computed and it determines the “weight” of neighbor node <em>B</em>’s “message” when central node <em>A</em> is doing Aggregation.</p>
<p>This attention score can be seen as a factor of importance. As supposed to the average aggregation where the weights are all <em>1/N</em> (where <em>N</em> denotes the number of neighbors node <em>A</em> has), <em>α</em> of <em>A</em> and <em>B</em> can be higher or lower than <em>1/N</em>, indicating a larger or smaller impact that the neighbor node <em>B</em> has on the central node <em>A</em>.</p>
<p>The number of <em>α</em> is computed by taking the node features of central nodes and neighbor nodes, and doing a sequence of transforms as below (here <em>i</em> corresponds to node <em>A</em>, and <em>j</em> corresponds to node <em>B</em>)</p>
<figure>
<img src="../images/1*b_4tis5cRqoPVGCIPXM2BA.png" alt="i is the central node, j is i’s neighbor node. W is a parameter matrix. a is a mechanism [4]"><figcaption aria-hidden="true">i is the central node, j is i’s neighbor node. W is a parameter matrix. a is a mechanism [4]</figcaption>
</figure>
<p><img src="../images/1*zn-PH1hH7SjC9mEaQY8OSA.png" alt="Ni is the neighbor node  of node i [4]" style="zoom:70%;" title=""></p>
<p>By using a single-layer feedforward neural network as the mechanism <em>a</em>, and applying the LeakyReLU nonlinearity, we have the expression for <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex" xmlns="http://www.w3.org/2000/svg" width="1.448ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 640 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g></g></g></svg></mjx-container></span>:</p>
<figure>
<img src="../images/1*8UmW43ZkomrEJ_udbEZrzw.png" alt="a is a parameter vector, W is a parameter matrix [4]"><figcaption aria-hidden="true">a is a parameter vector, W is a parameter matrix [4]</figcaption>
</figure>
<p>Without loss of generality, we could draw an example of the neighborhood of node <em>A</em>:</p>
<figure>
<img src="../images/1*v4tV6y6kj6HqXxa7pqaLeA.png" alt="neighborhood of node A"><figcaption aria-hidden="true">neighborhood of node A</figcaption>
</figure>
<p>And then the computation of attention scores can be visualized as:</p>
<figure>
<img src="../images/1*O7ug5qqk1rrEQr4Q6AipwA.jpeg" alt="The computation process of the attention score α of A and B"><figcaption aria-hidden="true">The computation process of the attention score α of A and B</figcaption>
</figure>
<p>We further adopt multi-head attention [5] to stabilize the learning process of self-attention. We use <em>K</em> independent attention mechanisms (or “heads”) to separately compute the updated node feature representations and then concatenate these representations. Assume we are using a Two-Head Attention, an example aggregation process will look like below, where the solid line and dotted line correspond to two different attention “head”, and the width of lines indicate attention scores.</p>
<figure>
<img src="../images/1*J_x1FOPF1QZvuRz4FR8AFQ.png" alt="Aggregation step of node A with Two-Head Attention mechanism"><figcaption aria-hidden="true">Aggregation step of node A with Two-Head Attention mechanism</figcaption>
</figure>
<p>The base model pipeline we applied is shown below.</p>
<figure>
<img src="../images/1*4BWgzj1hJCKBmuPaYM9edQ.png" alt="Base GAT model pipeline"><figcaption aria-hidden="true">Base GAT model pipeline</figcaption>
</figure>
<h1 id="tricks">Tricks</h1>
<p>Upon the base GAT model, we also added several tricks that were found useful in GNNs. It’s helpful to know about these commonly used tricks, and when you’re building a GNN of your own, give them a try and they might boost your model’s performance. We will walk you through these tricks and introduce their effect on the overall performance later.</p>
<h2 id="enrich-node-features-with-node2vec-embeddings">Enrich node features with Node2Vec embeddings</h2>
<p>Node features provided by the dataset itself do not contain information about the graph structure. Therefore, it sounds like a good idea to enrich the node features with structural knowledge. Node2Vec is a popular method to learn node features from the graph structure without the use of any external supervision [6].</p>
<p>Through simulating biased random walks, Node2Vec learns multi-hop neighborhood structure effectively. As Node2Vec is not the main focus of this tutorial, we will stop here and leave interested readers to the <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1607.00653">Node2Vec</a> paper.</p>
<figure>
<img src="../images/1*7m2BR6FA6tR3niv5j6uhiw.png" alt="Random walk of different styles [6]"><figcaption aria-hidden="true">Random walk of different styles [6]</figcaption>
</figure>
<p>We directly leverage Node2Vec implemented in PyTorch Geometric to train the embeddings. For implementation details, you can read the source code of <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/models/node2vec.html">Node2Vec in PyTorch Geometric</a>.</p>
<p>To use the learned features (vectors of length 128), we concatenate them with the node features provided by the dataset (also vectors of length 128) and feed them into the network.</p>
<p>Here’s a code snippet showing our implementation of Node2Vec:</p>
<figure>
<img src="../images/1*bHWMUfDDi94D2gxp1x7ELg.png" alt="Node2Vec implementation code snippet"><figcaption aria-hidden="true">Node2Vec implementation code snippet</figcaption>
</figure>
<h2 id="gat-variant">GAT Variant</h2>
<p>GAT is a classical network structure for GNN, and there have been some variants. Bag of tricks [7] borrowed the idea from Graph Convolutional Network (GCN) [8] with <em>Symmetric Normalized Adjacency Matrix</em> and applied it to GAT.</p>
<p>Say we write the update rules of traditional GAT in matrix form (for simplicity, we discuss the single-head attention scenario):</p>
<figure>
<img src="../images/1*nSxApmuebwqAbr165c-Aqw.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>For clarity we write down the definition of the attention matrix:</p>
<figure>
<img src="../images/1*32XWPlXPNrqYqYcbomn_QQ.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>Then Bag of tricks added a residual block to the layer and also normalized the attention matrix:</p>
<figure>
<img src="../images/1*W7MIMlGg_zK9g9hT59eYxQ.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>Where:</p>
<figure>
<img src="../images/1*8CpUb1KBezF3NkUkPbGqtQ.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>In order words, we first add self-loops to the graph and then calculate the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Degree_matrix">degree matrix</a> (<em>D</em>) and attention matrix. (By default, <em>A</em> and <em>D</em> do not contain self-loops)</p>
<p>To implement the GAT variant, we create a class inherited from PyTorch Geometric’s GATConv and rewrite the forward function, as shown in the code snippet below.</p>
<figure>
<img src="../images/1*rzSMW-MktIjFW9NhE6Kdug.png" alt="GAT variant implementation code snippet"><figcaption aria-hidden="true">GAT variant implementation code snippet</figcaption>
</figure>
<h2 id="label-usage">Label Usage</h2>
<p>In the node classification task, we have access to some nodes’ ground-truth labels and need to predict unknown nodes. Label Usage [7] is a popular trick which explicitly uses label information when predicting the test node labels.</p>
<p>Label usage is a data augmentation method. By leveraging the information of labels, the classifier could gather more correct information during the training process. When the training accuracy is below 100%, the label information of the misclassified samples is not contained in the model, despite the fact that they can provide additional information. At the same time, these misclassified samples could further mislead its neighbor, so adding correct information in the training process is very important.</p>
<p>In the label usage algorithm,<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex" xmlns="http://www.w3.org/2000/svg" width="2.047ex" height="2.059ex" role="img" focusable="false" viewBox="0 -705 904.6 910"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g></g></svg></mjx-container> denotes the GNN. We concatenate the input feature and the one-hot ground truth vector together as the input (if no ground truth, then the one-hot vector is replaced by an all-zero vector). After getting the predicted outputs (soft labels), we assigned these soft labels to unlabelled nodes.</p>
<figure>
<img src="../images/1*FYAUsOD35Shq-XxxIB5jFQ.png" alt="GAT variant implementation code snippet"><figcaption aria-hidden="true">GAT variant implementation code snippet</figcaption>
</figure>
<h2 id="correct-and-smooth">Correct and Smooth</h2>
<p>Correct and Smooth[9] (C&amp;S) is a recent state-of-the-art classification method, which uses the graph structure to do post-processing. It follows three steps:</p>
<ol type="1">
<li>Train a base predictor and use it to predict soft labels for all nodes.</li>
</ol>
<p>The base predictor could be any type of model that generates a soft label for each node. For example, in our task, we choose GAT as our base model to classify arXiv papers.</p>
<ol start="2" type="1">
<li>Correct step:</li>
</ol>
<p>In this step, we calculate the training residual, which is the difference between a ground-truth label and the predicted soft label. If a node doesn’t have a label (which means it is in the test set), the residual is a zero vector. Then we diffuse the training residual along with the graph structure. The diffusion step will use the following formula:</p>
<figure>
<img src="../images/1*3ep-c4n_NUWb6t1zbSUWQQ.png" alt="E^(t) is the training residual during t-th diffusion iteration, A is the diffusion matrix, and α is a parameter"><figcaption aria-hidden="true">E^(t) is the training residual during t-th diffusion iteration, A is the diffusion matrix, and α is a parameter</figcaption>
</figure>
<p>The output of the correct step is a combination of soft label and diffused error.</p>
<p>Here’s a GIF to illustrate the correct step:</p>
<figure>
<img src="../images/1*a69kNZrttkXw-1GACQC9Lw.gif" alt="Illustration of the Correct Step"><figcaption aria-hidden="true">Illustration of the Correct Step</figcaption>
</figure>
<ol start="3" type="1">
<li>Smooth step:</li>
</ol>
<p>In the smooth step, we use the ground-truth label and output of the correct step as input. Then it diffuses the label along with the graph structure. The label diffusion process can be described with the following formula:</p>
<figure>
<img src="../images/1*Il61jcl1NwHt7i6slqE4wA.png" alt="Z^(t) is the node label during t-th diffusion iteration, A is the diffusion matrix, and α is a parameter"><figcaption aria-hidden="true">Z^(t) is the node label during t-th diffusion iteration, A is the diffusion matrix, and α is a parameter</figcaption>
</figure>
<p>Here’s a GIF to illustrate the smooth step:</p>
<figure>
<img src="../images/1*F8kA6QHwtZEllQ57xRbw5w.gif" alt="Illustration of the Smooth Step"><figcaption aria-hidden="true">Illustration of the Smooth Step</figcaption>
</figure>
<p>Here is a pipeline showing the C&amp;S post-processing method.</p>
<figure>
<img src="../images/1*4b4p1PHQydcTS5uIRI506g.png" alt="Pipeline of C&S"><figcaption aria-hidden="true">Pipeline of C&amp;S</figcaption>
</figure>
<p>Please refer to the code snippet for implement details:</p>
<figure>
<img src="../images/1*zoV3WcUIQy34X7dEMlxAKQ.png" alt="C&S implement code snippet"><figcaption aria-hidden="true">C&amp;S implement code snippet</figcaption>
</figure>
<hr>
<p>Let’s take a break here and see how far we’ve got! Till now, our base model has added 4 tricks (add node2vec embeddings, modify GAT architecture, label usage, C&amp;S). The current pipeline of our model is shown below. The orange box represents the modification of the GAT model, the yellow box represents adding node2vec embeddings, the green box represents label usage, and the blue box represents C&amp;S.</p>
<figure>
<img src="../images/1*v4eVJMaamoZooqJc4NbzLg.png" alt="Our model pipeline after adding 4 tricks"><figcaption aria-hidden="true">Our model pipeline after adding <em>4</em> tricks</figcaption>
</figure>
<hr>
<h2 id="self-kd">Self-KD</h2>
<p>Knowledge Distillation (KD) is a model compression method in which a small model is trained to mimic a pre-trained, larger model (or ensemble of models). A common approach is to induce an extra loss with the predictions from a stronger model as labels. Self-KD is a trick that originated from the idea of KD. Sometimes, if we first train a model and then use it as the teacher model to train a second model in a KD fashion, the second model would perform better.</p>
<p>Below is an illustration of our complete model after adding all the tricks we mentioned above. And let’s get started on the experiments!</p>
<figure>
<img src="../images/1*3aKryC8HGOeEkIRZhY3utg.png" alt="The complete model after adding all tricks mentioned above"><figcaption aria-hidden="true">The complete model after adding all tricks mentioned above</figcaption>
</figure>
<h1 id="experiments">Experiments</h1>
<p>We use <a target="_blank" rel="noopener" href="https://pytorch.org/">PyTorch</a> and the <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/">PyTorch Geometric</a> library to implement our model and train it with Google Colab. We keep our model structure, learning schedule, etc., mostly the same as the setting of [10], though due to memory constraint we have to reduce the hidden layer size of GAT.</p>
<h2 id="training-process">Training Process</h2>
<p>One example training process is shown in the following picture. During the training process, the training loss gradually decreases, while the test accuracy fluctuates. The test accuracy of this example training process is about 0.73. Compared to the top methods on the <a target="_blank" rel="noopener" href="https://ogb.stanford.edu/docs/leader_nodeprop/#ogbn-arxiv">OGB leaderboard</a> with the same dataset, our model achieves similar high accuracy.</p>
<figure>
<img src="../images/1*9d_Pce0iz3Wf8eO6ZatF2g.png" alt="Training process"><figcaption aria-hidden="true">Training process</figcaption>
</figure>
<p>We further visualized the training process on the GAT model in the first 500 epochs. After using <a target="_blank" rel="noopener" href="https://lvdmaaten.github.io/tsne/">t-SNE</a>, a technique for dimensionality reduction, to map the embedding to 2-dimensional space, the GIF shows how the hidden embedding after the first GAT layer changes during the training process. The widths of edges show the attention scores in GAT. From epoch 0 to epoch 499, the nodes belonging to the same class gradually group together. At the same time, the attention mechanism generates some important attention edges during this process.</p>
<figure>
<img src="../images/1*R89SumE8o1gAgjL3UfHShg.gif" alt="The GIF showing our training process"><figcaption aria-hidden="true">The GIF showing our training process</figcaption>
</figure>
<h1 id="results">Results</h1>
<p>We designed our experiments in an incremental way. In the chart below, every row consists of one more trick of the previous row, while the first row is the GAT baseline setting with no bells and whistles.</p>
<p>Our experimental results are shown in the table.</p>
<figure>
<img src="../images/1*ioZaBIk7oXKfHlJIK5dAPA.png" alt="Validation and test results of our models (figures in the parentheses show the improvements from baseline)"><figcaption aria-hidden="true">Validation and test results of our models (figures in the parentheses show the improvements from baseline)</figcaption>
</figure>
<p>The comparison of different models can also be seen clearly in the figure below.</p>
<figure>
<img src="../images/1*vjKg8wG7Pul5F_7VtTHm1g.png" alt="Experiment result of different model settings"><figcaption aria-hidden="true">Experiment result of different model settings</figcaption>
</figure>
<p>We can observe that:</p>
<ul>
<li>Training with Node2Vec embeddings improves both validation accuracy and test accuracy by about 1 point. Though not shown in this chart, the training process also converged noticeably faster.</li>
<li>Adding residual connections and normalizing the attention matrix together brought tiny improvement. Since we only used 3 layers of GAT, residual connections may not be as useful as they are in deep models.</li>
<li>Label usage and C&amp;S further boosted the performance by 0.3% and 0.5%, respectively. These two tricks both involve leveraging ground truth labels, and they may have similar effects on the learning process — using neighbors with ground truth to guide prediction.</li>
<li>At last, experiments show self-KD brought no performance gain. We must point out that, averaging the outcome of 5 runs is still not statistically stable enough to claim that self-KD is not helpful in our setting, but chances are high that they are not as significant as other tricks.</li>
</ul>
<p><strong>The final result compared to leaderboard data:</strong></p>
<p>Our results are lower than the numbers on the leaderboard (~0.5%), probably because of two reasons:</p>
<ul>
<li>The author used one V100 GPU for training, which supports more parameters in the hidden layer of GAT (64 v.s. 256)</li>
<li>Randomness</li>
</ul>
<h1 id="conclusion">Conclusion</h1>
<p>In this blog, we reproduced the work of [10] and deliver a thorough introduction and analysis. In detail, we implemented the Graph Attention Network [4] and several commonly used tricks to challenge the node classification task on the ogbn-arxiv dataset. Our experiments show satisfactory results on this dataset. At the same time, we explored the effectiveness of different tricks proposed or introduced in the paper. From our experiments, we found that Node2Vec embeddings, label usage, and C&amp;S achieved noticeable improvements on the task while changing the network structure of GAT and leveraging self-KD barely increases the accuracy.</p>
<p>Going from top to bottom of the ogbn-arxiv leaderboard we can observe an interesting fact: leading methods use a bunch of tricks. Tricks may not bring consistent gain across all tasks, but if you are not satisfied with your model, just give them a try and wait for a surprise!</p>
<h1 id="references">References</h1>
<ol type="1">
<li>Wang, K., Shen, Z., Huang, C., Wu, C.-H., Dong, Y., &amp; Kanakia, A. (2020). Microsoft Academic Graph: When experts are not enough. <em>Quantitative Science Studies</em>, <em>1</em>(1), 396–413. https://doi.org/10.1162/qss_a_00021</li>
<li>Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S. &amp; Dean, J. (2013). Distributed Representations of Words and Phrases and their Compositionality. In <em>NIPS</em> (pp. 3111–3119) . Curran Associates, Inc. .</li>
<li>Scarselli, F., Gori, M., Ah Chung Tsoi, Hagenbuchner, M., &amp; Monfardini, G. (2009). The Graph Neural Network Model. <em>IEEE Transactions on Neural Networks</em>, <em>20</em>(1), 61–80. https://doi.org/10.1109/tnn.2008.2005605‌</li>
<li>Veličković, P., Cucurull, G., Casanova, A., Romero, A., Liò, P. &amp; Bengio, Y. (2017). Graph Attention Networks. <em>ICLR 2018</em>, .</li>
<li>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł. &amp; Polosukhin, I. (2017). Attention is All you Need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan &amp; R. Garnett (ed.), <em>Advances in Neural Information Processing Systems 30</em> (pp. 5998–6008) . Curran Associates, Inc. .</li>
<li>Grover, A. &amp; Leskovec, J. (2016). node2vec: Scalable Feature Learning for Networks.. <em>CoRR</em>, abs/1607.00653.</li>
<li>Wang, Y., Jin, J., Zhang, W., Yu, Y., Zhang, Z., &amp; Wipf, D. (2021). Bag of Tricks for Node Classification with Graph Neural Networks. <em>arXiv preprint arXiv:2103.13355</em>.</li>
<li>Kipf, T. N. &amp; Welling, M. (2016). Semi-Supervised Classification with Graph Convolutional Networks. <em>5th International Conference on Learning Representations</em>.</li>
<li>Huang, Q., He, H., Singh, A., Lim, S. N., &amp; Benson, A. R. (2020). Combining label propagation and simple models out-performs graph neural networks. <em>arXiv preprint arXiv:2010.13993</em>.</li>
<li>Chi, H., Wang, Y., Hao, Q., &amp; Xia, H. (2021). Residual Network and Embedding Usage: New Tricks of Node Classification with Graph Convolutional Networks. <em>arXiv preprint arXiv:2105.08330</em>.</li>
</ol>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><em></em><a class="button is-default" href="/posts/15af85cd.html" title="CS224W-Review"><span class="has-text-weight-semibold">Next: CS224W-Review</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="Haojen/Claudia-theme-blog" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/wwwjn"><i class="iconfont icon-github"></i></a><!-- Ins--><!-- RSS--><!-- 知乎--><!-- 领英--><a title="linkedin" target="_blank" rel="noopener nofollow" href="//www.linkedin.com/in/wangjiani"><i class="iconfont icon-linkedin"></i></a><!-- 脸书--></section><p><span>Copyright ©</span><span> Jiani Wang 2022</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/post.js"></script></body></html>